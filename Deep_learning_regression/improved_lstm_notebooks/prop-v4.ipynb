{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "files = glob.glob(\"../../datasets/prop-1.csv\", recursive = True)\n",
    "ant_master = pd.concat(map(pd.read_csv, files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>version</th>\n",
       "      <th>wmc</th>\n",
       "      <th>dit</th>\n",
       "      <th>noc</th>\n",
       "      <th>cbo</th>\n",
       "      <th>rfc</th>\n",
       "      <th>lcom</th>\n",
       "      <th>ca</th>\n",
       "      <th>ce</th>\n",
       "      <th>...</th>\n",
       "      <th>dam</th>\n",
       "      <th>moa</th>\n",
       "      <th>mfa</th>\n",
       "      <th>cam</th>\n",
       "      <th>ic</th>\n",
       "      <th>cbm</th>\n",
       "      <th>amc</th>\n",
       "      <th>max_cc</th>\n",
       "      <th>avg_cc</th>\n",
       "      <th>bug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prop-1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prop-1</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>44</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.905172</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>20.583333</td>\n",
       "      <td>8</td>\n",
       "      <td>2.0833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prop-1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.2000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prop-1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prop-1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.625000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18466</th>\n",
       "      <td>prop-1</td>\n",
       "      <td>185</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>67</td>\n",
       "      <td>96</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.529412</td>\n",
       "      <td>6</td>\n",
       "      <td>2.6471</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18467</th>\n",
       "      <td>prop-1</td>\n",
       "      <td>185</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>49</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.319444</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.888889</td>\n",
       "      <td>3</td>\n",
       "      <td>1.3333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18468</th>\n",
       "      <td>prop-1</td>\n",
       "      <td>185</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>6</td>\n",
       "      <td>2.1667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18469</th>\n",
       "      <td>prop-1</td>\n",
       "      <td>185</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18470</th>\n",
       "      <td>prop-1</td>\n",
       "      <td>185</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.545455</td>\n",
       "      <td>6</td>\n",
       "      <td>1.9091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18471 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Name  version  wmc  dit  noc  cbo  rfc  lcom  ca  ce  ...       dam  \\\n",
       "0      prop-1        4    2    4    0    2    5     1   0   2  ...  1.000000   \n",
       "1      prop-1        4   12    4    1   19   44    66   2  18  ...  0.000000   \n",
       "2      prop-1        4   10    4    0   13   48    45   4  13  ...  1.000000   \n",
       "3      prop-1        4    2    3    0    5    7     1   0   5  ...  1.000000   \n",
       "4      prop-1        4    8    1    0    4   38     0   3   1  ...  0.500000   \n",
       "...       ...      ...  ...  ...  ...  ...  ...   ...  ..  ..  ...       ...   \n",
       "18466  prop-1      185   17    1    0   24   67    96   9  15  ...  0.150000   \n",
       "18467  prop-1      185    9    1    0   25   49    14   7  18  ...  0.333333   \n",
       "18468  prop-1      185    6    3    0   10   29     0   0  10  ...  0.800000   \n",
       "18469  prop-1      185    5    5    0   28    9    10  26   2  ...  1.000000   \n",
       "18470  prop-1      185   11    1    0   54   34     9  51   3  ...  0.666667   \n",
       "\n",
       "       moa       mfa       cam  ic  cbm        amc  max_cc  avg_cc  bug  \n",
       "0        0  0.941176  0.750000   1    1  10.500000       3  1.5000    0  \n",
       "1        0  0.905172  0.350000   2    3  20.583333       8  2.0833    0  \n",
       "2        0  0.918919  0.500000   2    3  19.100000       4  1.2000    0  \n",
       "3        0  0.933333  0.750000   1    1  11.500000       4  2.0000    1  \n",
       "4        0  0.000000  0.285714   0    0  30.625000       2  0.8750    0  \n",
       "...    ...       ...       ...  ..  ...        ...     ...     ...  ...  \n",
       "18466    0  0.000000  0.250000   0    0  41.529412       6  2.6471    1  \n",
       "18467    0  0.000000  0.319444   0    0  29.888889       3  1.3333    0  \n",
       "18468    0  0.818182  0.400000   0    0  45.500000       6  2.1667    0  \n",
       "18469    0  0.962963  0.650000   1    1   4.400000       1  0.2000    0  \n",
       "18470    1  0.000000  0.400000   0    0  25.545455       6  1.9091    0  \n",
       "\n",
       "[18471 rows x 23 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ant_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(ant_master, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_norm = ['wmc', 'dit', 'noc', 'cbo', 'rfc', 'lcom', 'ca', 'ce', 'npm', 'lcom3', 'loc', 'dam', 'moa', 'mfa', 'cam', 'ic', 'cbm', 'amc', 'max_cc', 'avg_cc']\n",
    "x_train = train[cols_to_norm]\n",
    "x_test = test[cols_to_norm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wmc</th>\n",
       "      <th>dit</th>\n",
       "      <th>noc</th>\n",
       "      <th>cbo</th>\n",
       "      <th>rfc</th>\n",
       "      <th>lcom</th>\n",
       "      <th>ca</th>\n",
       "      <th>ce</th>\n",
       "      <th>npm</th>\n",
       "      <th>lcom3</th>\n",
       "      <th>loc</th>\n",
       "      <th>dam</th>\n",
       "      <th>moa</th>\n",
       "      <th>mfa</th>\n",
       "      <th>cam</th>\n",
       "      <th>ic</th>\n",
       "      <th>cbm</th>\n",
       "      <th>amc</th>\n",
       "      <th>max_cc</th>\n",
       "      <th>avg_cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16174</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>286</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92.666667</td>\n",
       "      <td>8</td>\n",
       "      <td>2.6667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17310</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>127</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.833333</td>\n",
       "      <td>2</td>\n",
       "      <td>1.1667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7243</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3477</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10313</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12719</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4421</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>74</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.666667</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15514</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>59</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.250000</td>\n",
       "      <td>6</td>\n",
       "      <td>1.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2906</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>15</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8427</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>132</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.800000</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14776 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       wmc  dit  noc  cbo  rfc  lcom  ca  ce  npm     lcom3  loc       dam  \\\n",
       "16174    3    1    0   16   73     1   0  16    2  0.900000  286  0.600000   \n",
       "17310    6    1    0   14   23     0   1  13    5  0.300000  127  1.000000   \n",
       "7243     0    1    0    0    0     0   0   0    0  2.000000    2  0.000000   \n",
       "3477     8    1    0    7    8    28   0   7    8  2.000000    8  0.000000   \n",
       "10313    2    4    0    1    4     1   0   1    1  2.000000    9  0.000000   \n",
       "...    ...  ...  ...  ...  ...   ...  ..  ..  ...       ...  ...       ...   \n",
       "12719    2    3    0   11   17     1   0  11    2  1.000000  145  0.000000   \n",
       "4421     3    3    0    6   19     1   0   6    1  1.000000   74  0.666667   \n",
       "15514   16    1    0    8   59    42   2   6   11  0.848485  543  1.000000   \n",
       "2906     3    5    0    3    5     3   1   2    3  1.500000   15  1.000000   \n",
       "8427     5    2    0    6   29     0   1   5    4  0.666667  132  0.666667   \n",
       "\n",
       "       moa       mfa       cam  ic  cbm        amc  max_cc  avg_cc  \n",
       "16174    0  0.000000  0.666667   0    0  92.666667       8  2.6667  \n",
       "17310    1  0.000000  0.583333   0    0  19.833333       2  1.1667  \n",
       "7243     0  0.000000  0.000000   0    0   0.000000       0  0.0000  \n",
       "3477     0  0.000000  0.500000   0    0   0.000000       1  1.0000  \n",
       "10313    0  0.933333  0.750000   1    1   3.500000       1  0.5000  \n",
       "...    ...       ...       ...  ..  ...        ...     ...     ...  \n",
       "12719    0  0.947368  0.600000   0    0  71.000000       1  0.5000  \n",
       "4421     0  0.928571  0.750000   1    1  22.666667       6  2.0000  \n",
       "15514    0  0.000000  0.293333   0    0  32.250000       6  1.8125  \n",
       "2906     0  0.962963  0.666667   1    1   3.666667       1  0.3333  \n",
       "8427     0  0.571429  0.500000   0    0  24.800000       5  2.0000  \n",
       "\n",
       "[14776 rows x 20 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wmc</th>\n",
       "      <th>dit</th>\n",
       "      <th>noc</th>\n",
       "      <th>cbo</th>\n",
       "      <th>rfc</th>\n",
       "      <th>lcom</th>\n",
       "      <th>ca</th>\n",
       "      <th>ce</th>\n",
       "      <th>npm</th>\n",
       "      <th>lcom3</th>\n",
       "      <th>loc</th>\n",
       "      <th>dam</th>\n",
       "      <th>moa</th>\n",
       "      <th>mfa</th>\n",
       "      <th>cam</th>\n",
       "      <th>ic</th>\n",
       "      <th>cbm</th>\n",
       "      <th>amc</th>\n",
       "      <th>max_cc</th>\n",
       "      <th>avg_cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5041</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>194</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>46.250000</td>\n",
       "      <td>9</td>\n",
       "      <td>2.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14466</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>243</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46.400000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2901</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>28</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7222</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>68</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>0.891667</td>\n",
       "      <td>492</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.076923</td>\n",
       "      <td>3</td>\n",
       "      <td>1.2308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13061</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>39</td>\n",
       "      <td>741</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>39</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.623932</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>75</td>\n",
       "      <td>247</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>0.902899</td>\n",
       "      <td>782</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0</td>\n",
       "      <td>0.654321</td>\n",
       "      <td>0.121588</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>23.483871</td>\n",
       "      <td>23</td>\n",
       "      <td>2.4839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3695 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       wmc  dit  noc  cbo  rfc  lcom  ca  ce  npm     lcom3  loc       dam  \\\n",
       "5041     2    3    0    5    4     1   5   0    2  2.000000   11  1.000000   \n",
       "1101     4    4    0   18   39     4   0  18    2  0.933333  194  0.200000   \n",
       "14995    4    1    0   14    4     6  12   2    4  2.000000    4  0.000000   \n",
       "14466    5    2    2    9   35     8   2   7    1  1.166667  243  1.000000   \n",
       "2901     5    5    0   56    9    10  54   2    5  1.250000   28  1.000000   \n",
       "...    ...  ...  ...  ...  ...   ...  ..  ..  ...       ...  ...       ...   \n",
       "7222    13    1    0   18   68    46   1  17   12  0.891667  492  0.800000   \n",
       "13061    1    1    0    0    5     0   0   0    0  2.000000   20  0.000000   \n",
       "373      2    1    0    6   10     0   1   5    2  0.000000   28  1.000000   \n",
       "2040    39    1    0   23   39   741  20   3   39  2.000000   39  0.000000   \n",
       "3167    31    3    0   11   75   247   0  11   27  0.902899  782  0.347826   \n",
       "\n",
       "       moa       mfa       cam  ic  cbm        amc  max_cc  avg_cc  \n",
       "5041     0  1.000000  0.666667   0    0   4.000000       0  0.0000  \n",
       "1101     0  0.920000  0.444444   1    3  46.250000       9  2.5000  \n",
       "14995    0  0.000000  0.875000   0    0   0.000000       1  1.0000  \n",
       "14466    0  0.823529  0.750000   0    0  46.400000       5  1.4000  \n",
       "2901     0  0.962963  0.650000   1    1   4.400000       1  0.2000  \n",
       "...    ...       ...       ...  ..  ...        ...     ...     ...  \n",
       "7222     2  0.000000  0.277778   0    0  36.076923       3  1.2308  \n",
       "13061    0  0.000000  0.000000   0    0  12.000000       0  0.0000  \n",
       "373      0  0.000000  0.666667   0    0  12.500000       1  0.5000  \n",
       "2040     0  0.000000  0.623932   0    0   0.000000       1  1.0000  \n",
       "3167     0  0.654321  0.121588   3   20  23.483871      23  2.4839  \n",
       "\n",
       "[3695 rows x 20 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['bug']\n",
    "y_test = test['bug']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16174    0\n",
       "17310    0\n",
       "7243     0\n",
       "3477     0\n",
       "10313    0\n",
       "        ..\n",
       "12719    0\n",
       "4421     0\n",
       "15514    1\n",
       "2906     0\n",
       "8427     0\n",
       "Name: bug, Length: 14776, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5041     0\n",
       "1101     0\n",
       "14995    0\n",
       "14466    0\n",
       "2901     0\n",
       "        ..\n",
       "7222     0\n",
       "13061    0\n",
       "373      0\n",
       "2040     2\n",
       "3167     0\n",
       "Name: bug, Length: 3695, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_np = np.array(x_train)\n",
    "x_test_np = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.        ,  1.        ,  0.        , ..., 92.66666667,\n",
       "         8.        ,  2.6667    ],\n",
       "       [ 6.        ,  1.        ,  0.        , ..., 19.83333333,\n",
       "         2.        ,  1.1667    ],\n",
       "       [ 0.        ,  1.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [16.        ,  1.        ,  0.        , ..., 32.25      ,\n",
       "         6.        ,  1.8125    ],\n",
       "       [ 3.        ,  5.        ,  0.        , ...,  3.66666667,\n",
       "         1.        ,  0.3333    ],\n",
       "       [ 5.        ,  2.        ,  0.        , ..., 24.8       ,\n",
       "         5.        ,  2.        ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.        ,  3.        ,  0.        , ...,  4.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 4.        ,  4.        ,  0.        , ..., 46.25      ,\n",
       "         9.        ,  2.5       ],\n",
       "       [ 4.        ,  1.        ,  0.        , ...,  0.        ,\n",
       "         1.        ,  1.        ],\n",
       "       ...,\n",
       "       [ 2.        ,  1.        ,  0.        , ..., 12.5       ,\n",
       "         1.        ,  0.5       ],\n",
       "       [39.        ,  1.        ,  0.        , ...,  0.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [31.        ,  3.        ,  0.        , ..., 23.48387097,\n",
       "        23.        ,  2.4839    ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.reshape(x_train_np, (x_train_np.shape[0], 1, x_train_np.shape[1]))\n",
    "test_x = np.reshape(x_test_np, (x_test_np.shape[0], 1, x_test_np.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = y_train.to_numpy()\n",
    "test_y = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 3.        ,  1.        ,  0.        , ..., 92.66666667,\n",
       "          8.        ,  2.6667    ]],\n",
       "\n",
       "       [[ 6.        ,  1.        ,  0.        , ..., 19.83333333,\n",
       "          2.        ,  1.1667    ]],\n",
       "\n",
       "       [[ 0.        ,  1.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[16.        ,  1.        ,  0.        , ..., 32.25      ,\n",
       "          6.        ,  1.8125    ]],\n",
       "\n",
       "       [[ 3.        ,  5.        ,  0.        , ...,  3.66666667,\n",
       "          1.        ,  0.3333    ]],\n",
       "\n",
       "       [[ 5.        ,  2.        ,  0.        , ..., 24.8       ,\n",
       "          5.        ,  2.        ]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 2, 0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designing and initializing the model.\n",
    "from keras.layers import LSTM, Dense, SimpleRNN\n",
    "# Designing and initializing the model.\n",
    "model = Sequential()\n",
    "model.add(LSTM(200, return_sequences=True))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(50, dropout = 0.2, return_sequences=True))\n",
    "model.add(LSTM(20, return_sequences=False))\n",
    "model.add(Dense(1, activation = 'relu'))\n",
    "model.compile(loss = 'mse' , optimizer = keras.optimizers.Adam(learning_rate=0.00001), metrics = ['mse', 'mae', tf.keras.metrics.RootMeanSquaredError(), tf.keras.metrics.MeanSquaredLogarithmicError()] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer ModuleWrapper has arguments in `__init__` and therefore must override `get_config`.\n",
      "Epoch 1/200\n",
      "462/462 [==============================] - 7s 5ms/step - loss: 1.3606 - mse: 1.3606 - mae: 0.3160 - root_mean_squared_error: 1.1665 - mean_squared_logarithmic_error: 0.1646\n",
      "Epoch 2/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.3265 - mse: 1.3265 - mae: 0.3588 - root_mean_squared_error: 1.1518 - mean_squared_logarithmic_error: 0.1526\n",
      "Epoch 3/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.2903 - mse: 1.2903 - mae: 0.4199 - root_mean_squared_error: 1.1359 - mean_squared_logarithmic_error: 0.1483\n",
      "Epoch 4/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.2741 - mse: 1.2741 - mae: 0.4631 - root_mean_squared_error: 1.1288 - mean_squared_logarithmic_error: 0.1528\n",
      "Epoch 5/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.2674 - mse: 1.2674 - mae: 0.4810 - root_mean_squared_error: 1.1258 - mean_squared_logarithmic_error: 0.1561\n",
      "Epoch 6/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.2609 - mse: 1.2609 - mae: 0.4818 - root_mean_squared_error: 1.1229 - mean_squared_logarithmic_error: 0.1554\n",
      "Epoch 7/200\n",
      "462/462 [==============================] - 3s 5ms/step - loss: 1.2549 - mse: 1.2549 - mae: 0.4841 - root_mean_squared_error: 1.1202 - mean_squared_logarithmic_error: 0.1554\n",
      "Epoch 8/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.2481 - mse: 1.2481 - mae: 0.4789 - root_mean_squared_error: 1.1172 - mean_squared_logarithmic_error: 0.1532\n",
      "Epoch 9/200\n",
      "462/462 [==============================] - 3s 6ms/step - loss: 1.2420 - mse: 1.2420 - mae: 0.4766 - root_mean_squared_error: 1.1144 - mean_squared_logarithmic_error: 0.1519\n",
      "Epoch 10/200\n",
      "462/462 [==============================] - 3s 6ms/step - loss: 1.2338 - mse: 1.2338 - mae: 0.4783 - root_mean_squared_error: 1.1108 - mean_squared_logarithmic_error: 0.1516\n",
      "Epoch 11/200\n",
      "462/462 [==============================] - 3s 6ms/step - loss: 1.2258 - mse: 1.2258 - mae: 0.4782 - root_mean_squared_error: 1.1072 - mean_squared_logarithmic_error: 0.1510\n",
      "Epoch 12/200\n",
      "462/462 [==============================] - 3s 6ms/step - loss: 1.2185 - mse: 1.2185 - mae: 0.4693 - root_mean_squared_error: 1.1039 - mean_squared_logarithmic_error: 0.1479\n",
      "Epoch 13/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.2104 - mse: 1.2104 - mae: 0.4692 - root_mean_squared_error: 1.1002 - mean_squared_logarithmic_error: 0.1474\n",
      "Epoch 14/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.2021 - mse: 1.2021 - mae: 0.4687 - root_mean_squared_error: 1.0964 - mean_squared_logarithmic_error: 0.1470\n",
      "Epoch 15/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.1920 - mse: 1.1920 - mae: 0.4645 - root_mean_squared_error: 1.0918 - mean_squared_logarithmic_error: 0.1452\n",
      "Epoch 16/200\n",
      "462/462 [==============================] - 3s 5ms/step - loss: 1.1835 - mse: 1.1835 - mae: 0.4637 - root_mean_squared_error: 1.0879 - mean_squared_logarithmic_error: 0.1450\n",
      "Epoch 17/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.1755 - mse: 1.1755 - mae: 0.4573 - root_mean_squared_error: 1.0842 - mean_squared_logarithmic_error: 0.1429\n",
      "Epoch 18/200\n",
      "462/462 [==============================] - 3s 6ms/step - loss: 1.1660 - mse: 1.1660 - mae: 0.4530 - root_mean_squared_error: 1.0798 - mean_squared_logarithmic_error: 0.1416\n",
      "Epoch 19/200\n",
      "462/462 [==============================] - 3s 5ms/step - loss: 1.1582 - mse: 1.1582 - mae: 0.4497 - root_mean_squared_error: 1.0762 - mean_squared_logarithmic_error: 0.1409\n",
      "Epoch 20/200\n",
      "462/462 [==============================] - 3s 5ms/step - loss: 1.1495 - mse: 1.1495 - mae: 0.4468 - root_mean_squared_error: 1.0721 - mean_squared_logarithmic_error: 0.1400\n",
      "Epoch 21/200\n",
      "462/462 [==============================] - 3s 6ms/step - loss: 1.1417 - mse: 1.1417 - mae: 0.4444 - root_mean_squared_error: 1.0685 - mean_squared_logarithmic_error: 0.1399\n",
      "Epoch 22/200\n",
      "462/462 [==============================] - 3s 6ms/step - loss: 1.1362 - mse: 1.1362 - mae: 0.4401 - root_mean_squared_error: 1.0659 - mean_squared_logarithmic_error: 0.1387\n",
      "Epoch 23/200\n",
      "462/462 [==============================] - 3s 8ms/step - loss: 1.1303 - mse: 1.1303 - mae: 0.4364 - root_mean_squared_error: 1.0631 - mean_squared_logarithmic_error: 0.1385\n",
      "Epoch 24/200\n",
      "462/462 [==============================] - 4s 8ms/step - loss: 1.1215 - mse: 1.1215 - mae: 0.4343 - root_mean_squared_error: 1.0590 - mean_squared_logarithmic_error: 0.1383\n",
      "Epoch 25/200\n",
      "462/462 [==============================] - 3s 6ms/step - loss: 1.1167 - mse: 1.1167 - mae: 0.4304 - root_mean_squared_error: 1.0567 - mean_squared_logarithmic_error: 0.1374\n",
      "Epoch 26/200\n",
      "462/462 [==============================] - 3s 6ms/step - loss: 1.1126 - mse: 1.1126 - mae: 0.4254 - root_mean_squared_error: 1.0548 - mean_squared_logarithmic_error: 0.1366\n",
      "Epoch 27/200\n",
      "462/462 [==============================] - 3s 6ms/step - loss: 1.1103 - mse: 1.1103 - mae: 0.4259 - root_mean_squared_error: 1.0537 - mean_squared_logarithmic_error: 0.1376\n",
      "Epoch 28/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.1016 - mse: 1.1016 - mae: 0.4211 - root_mean_squared_error: 1.0496 - mean_squared_logarithmic_error: 0.1362\n",
      "Epoch 29/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.1010 - mse: 1.1010 - mae: 0.4179 - root_mean_squared_error: 1.0493 - mean_squared_logarithmic_error: 0.1358\n",
      "Epoch 30/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0947 - mse: 1.0947 - mae: 0.4213 - root_mean_squared_error: 1.0463 - mean_squared_logarithmic_error: 0.1367\n",
      "Epoch 31/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0920 - mse: 1.0920 - mae: 0.4117 - root_mean_squared_error: 1.0450 - mean_squared_logarithmic_error: 0.1342\n",
      "Epoch 32/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0851 - mse: 1.0851 - mae: 0.4172 - root_mean_squared_error: 1.0417 - mean_squared_logarithmic_error: 0.1360\n",
      "Epoch 33/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0815 - mse: 1.0815 - mae: 0.4088 - root_mean_squared_error: 1.0399 - mean_squared_logarithmic_error: 0.1338\n",
      "Epoch 34/200\n",
      "462/462 [==============================] - 3s 5ms/step - loss: 1.0785 - mse: 1.0785 - mae: 0.4129 - root_mean_squared_error: 1.0385 - mean_squared_logarithmic_error: 0.1353\n",
      "Epoch 35/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0757 - mse: 1.0757 - mae: 0.4064 - root_mean_squared_error: 1.0372 - mean_squared_logarithmic_error: 0.1333\n",
      "Epoch 36/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0738 - mse: 1.0738 - mae: 0.4071 - root_mean_squared_error: 1.0363 - mean_squared_logarithmic_error: 0.1336\n",
      "Epoch 37/200\n",
      "462/462 [==============================] - 3s 6ms/step - loss: 1.0709 - mse: 1.0709 - mae: 0.4094 - root_mean_squared_error: 1.0348 - mean_squared_logarithmic_error: 0.1346\n",
      "Epoch 38/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0692 - mse: 1.0692 - mae: 0.4037 - root_mean_squared_error: 1.0340 - mean_squared_logarithmic_error: 0.1330\n",
      "Epoch 39/200\n",
      "462/462 [==============================] - 3s 6ms/step - loss: 1.0649 - mse: 1.0649 - mae: 0.4039 - root_mean_squared_error: 1.0319 - mean_squared_logarithmic_error: 0.1327\n",
      "Epoch 40/200\n",
      "462/462 [==============================] - 3s 7ms/step - loss: 1.0619 - mse: 1.0619 - mae: 0.4041 - root_mean_squared_error: 1.0305 - mean_squared_logarithmic_error: 0.1330\n",
      "Epoch 41/200\n",
      "462/462 [==============================] - 3s 5ms/step - loss: 1.0600 - mse: 1.0600 - mae: 0.4051 - root_mean_squared_error: 1.0296 - mean_squared_logarithmic_error: 0.1332\n",
      "Epoch 42/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0571 - mse: 1.0571 - mae: 0.4039 - root_mean_squared_error: 1.0281 - mean_squared_logarithmic_error: 0.1326\n",
      "Epoch 43/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0567 - mse: 1.0567 - mae: 0.4030 - root_mean_squared_error: 1.0280 - mean_squared_logarithmic_error: 0.1323\n",
      "Epoch 44/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0544 - mse: 1.0544 - mae: 0.3996 - root_mean_squared_error: 1.0268 - mean_squared_logarithmic_error: 0.1315\n",
      "Epoch 45/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0512 - mse: 1.0512 - mae: 0.4022 - root_mean_squared_error: 1.0253 - mean_squared_logarithmic_error: 0.1321\n",
      "Epoch 46/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0497 - mse: 1.0497 - mae: 0.4017 - root_mean_squared_error: 1.0245 - mean_squared_logarithmic_error: 0.1320\n",
      "Epoch 47/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0476 - mse: 1.0476 - mae: 0.3980 - root_mean_squared_error: 1.0235 - mean_squared_logarithmic_error: 0.1309\n",
      "Epoch 48/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0461 - mse: 1.0461 - mae: 0.3987 - root_mean_squared_error: 1.0228 - mean_squared_logarithmic_error: 0.1304\n",
      "Epoch 49/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0407 - mse: 1.0407 - mae: 0.4004 - root_mean_squared_error: 1.0202 - mean_squared_logarithmic_error: 0.1310\n",
      "Epoch 50/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0372 - mse: 1.0372 - mae: 0.4020 - root_mean_squared_error: 1.0184 - mean_squared_logarithmic_error: 0.1315\n",
      "Epoch 51/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0383 - mse: 1.0383 - mae: 0.4017 - root_mean_squared_error: 1.0189 - mean_squared_logarithmic_error: 0.1312\n",
      "Epoch 52/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0384 - mse: 1.0384 - mae: 0.3983 - root_mean_squared_error: 1.0190 - mean_squared_logarithmic_error: 0.1308\n",
      "Epoch 53/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0364 - mse: 1.0364 - mae: 0.3986 - root_mean_squared_error: 1.0180 - mean_squared_logarithmic_error: 0.1300\n",
      "Epoch 54/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0308 - mse: 1.0308 - mae: 0.3981 - root_mean_squared_error: 1.0153 - mean_squared_logarithmic_error: 0.1296\n",
      "Epoch 55/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0324 - mse: 1.0324 - mae: 0.4007 - root_mean_squared_error: 1.0161 - mean_squared_logarithmic_error: 0.1305\n",
      "Epoch 56/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0293 - mse: 1.0293 - mae: 0.3982 - root_mean_squared_error: 1.0145 - mean_squared_logarithmic_error: 0.1294\n",
      "Epoch 57/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0287 - mse: 1.0287 - mae: 0.3997 - root_mean_squared_error: 1.0143 - mean_squared_logarithmic_error: 0.1302\n",
      "Epoch 58/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0271 - mse: 1.0271 - mae: 0.3989 - root_mean_squared_error: 1.0135 - mean_squared_logarithmic_error: 0.1296\n",
      "Epoch 59/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0248 - mse: 1.0248 - mae: 0.3979 - root_mean_squared_error: 1.0123 - mean_squared_logarithmic_error: 0.1293\n",
      "Epoch 60/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0262 - mse: 1.0262 - mae: 0.3992 - root_mean_squared_error: 1.0130 - mean_squared_logarithmic_error: 0.1296\n",
      "Epoch 61/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0222 - mse: 1.0222 - mae: 0.3964 - root_mean_squared_error: 1.0111 - mean_squared_logarithmic_error: 0.1287\n",
      "Epoch 62/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0200 - mse: 1.0200 - mae: 0.3995 - root_mean_squared_error: 1.0100 - mean_squared_logarithmic_error: 0.1296\n",
      "Epoch 63/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0226 - mse: 1.0226 - mae: 0.3989 - root_mean_squared_error: 1.0112 - mean_squared_logarithmic_error: 0.1291\n",
      "Epoch 64/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0166 - mse: 1.0166 - mae: 0.3966 - root_mean_squared_error: 1.0083 - mean_squared_logarithmic_error: 0.1280\n",
      "Epoch 65/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0184 - mse: 1.0184 - mae: 0.3982 - root_mean_squared_error: 1.0092 - mean_squared_logarithmic_error: 0.1290\n",
      "Epoch 66/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0180 - mse: 1.0180 - mae: 0.3964 - root_mean_squared_error: 1.0090 - mean_squared_logarithmic_error: 0.1278\n",
      "Epoch 67/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0138 - mse: 1.0138 - mae: 0.3987 - root_mean_squared_error: 1.0069 - mean_squared_logarithmic_error: 0.1283\n",
      "Epoch 68/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0149 - mse: 1.0149 - mae: 0.3980 - root_mean_squared_error: 1.0074 - mean_squared_logarithmic_error: 0.1284\n",
      "Epoch 69/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0123 - mse: 1.0123 - mae: 0.3988 - root_mean_squared_error: 1.0061 - mean_squared_logarithmic_error: 0.1285\n",
      "Epoch 70/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0104 - mse: 1.0104 - mae: 0.3954 - root_mean_squared_error: 1.0052 - mean_squared_logarithmic_error: 0.1273\n",
      "Epoch 71/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0120 - mse: 1.0120 - mae: 0.3990 - root_mean_squared_error: 1.0060 - mean_squared_logarithmic_error: 0.1286\n",
      "Epoch 72/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0083 - mse: 1.0083 - mae: 0.3942 - root_mean_squared_error: 1.0041 - mean_squared_logarithmic_error: 0.1266\n",
      "Epoch 73/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0045 - mse: 1.0045 - mae: 0.3994 - root_mean_squared_error: 1.0022 - mean_squared_logarithmic_error: 0.1287\n",
      "Epoch 74/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0073 - mse: 1.0073 - mae: 0.3961 - root_mean_squared_error: 1.0037 - mean_squared_logarithmic_error: 0.1273\n",
      "Epoch 75/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0053 - mse: 1.0053 - mae: 0.3956 - root_mean_squared_error: 1.0027 - mean_squared_logarithmic_error: 0.1269\n",
      "Epoch 76/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0024 - mse: 1.0024 - mae: 0.3983 - root_mean_squared_error: 1.0012 - mean_squared_logarithmic_error: 0.1282\n",
      "Epoch 77/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9998 - mse: 0.9998 - mae: 0.3928 - root_mean_squared_error: 0.9999 - mean_squared_logarithmic_error: 0.1262\n",
      "Epoch 78/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0033 - mse: 1.0033 - mae: 0.3951 - root_mean_squared_error: 1.0016 - mean_squared_logarithmic_error: 0.1269\n",
      "Epoch 79/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0028 - mse: 1.0028 - mae: 0.3938 - root_mean_squared_error: 1.0014 - mean_squared_logarithmic_error: 0.1264\n",
      "Epoch 80/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0009 - mse: 1.0009 - mae: 0.3968 - root_mean_squared_error: 1.0005 - mean_squared_logarithmic_error: 0.1273\n",
      "Epoch 81/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9982 - mse: 0.9982 - mae: 0.3954 - root_mean_squared_error: 0.9991 - mean_squared_logarithmic_error: 0.1269\n",
      "Epoch 82/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 1.0016 - mse: 1.0016 - mae: 0.3933 - root_mean_squared_error: 1.0008 - mean_squared_logarithmic_error: 0.1262\n",
      "Epoch 83/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9965 - mse: 0.9965 - mae: 0.3929 - root_mean_squared_error: 0.9983 - mean_squared_logarithmic_error: 0.1256\n",
      "Epoch 84/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9966 - mse: 0.9966 - mae: 0.3961 - root_mean_squared_error: 0.9983 - mean_squared_logarithmic_error: 0.1270\n",
      "Epoch 85/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9947 - mse: 0.9947 - mae: 0.3959 - root_mean_squared_error: 0.9973 - mean_squared_logarithmic_error: 0.1266\n",
      "Epoch 86/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9949 - mse: 0.9949 - mae: 0.3903 - root_mean_squared_error: 0.9974 - mean_squared_logarithmic_error: 0.1251\n",
      "Epoch 87/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9942 - mse: 0.9942 - mae: 0.3948 - root_mean_squared_error: 0.9971 - mean_squared_logarithmic_error: 0.1259\n",
      "Epoch 88/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9943 - mse: 0.9943 - mae: 0.3948 - root_mean_squared_error: 0.9971 - mean_squared_logarithmic_error: 0.1267\n",
      "Epoch 89/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9913 - mse: 0.9913 - mae: 0.3920 - root_mean_squared_error: 0.9957 - mean_squared_logarithmic_error: 0.1258\n",
      "Epoch 90/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9900 - mse: 0.9900 - mae: 0.3949 - root_mean_squared_error: 0.9950 - mean_squared_logarithmic_error: 0.1265\n",
      "Epoch 91/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9921 - mse: 0.9921 - mae: 0.3897 - root_mean_squared_error: 0.9960 - mean_squared_logarithmic_error: 0.1249\n",
      "Epoch 92/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9900 - mse: 0.9900 - mae: 0.3969 - root_mean_squared_error: 0.9950 - mean_squared_logarithmic_error: 0.1266\n",
      "Epoch 93/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9894 - mse: 0.9894 - mae: 0.3925 - root_mean_squared_error: 0.9947 - mean_squared_logarithmic_error: 0.1258\n",
      "Epoch 94/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9834 - mse: 0.9834 - mae: 0.3919 - root_mean_squared_error: 0.9917 - mean_squared_logarithmic_error: 0.1247\n",
      "Epoch 95/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9887 - mse: 0.9887 - mae: 0.3928 - root_mean_squared_error: 0.9944 - mean_squared_logarithmic_error: 0.1257\n",
      "Epoch 96/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9865 - mse: 0.9865 - mae: 0.3916 - root_mean_squared_error: 0.9932 - mean_squared_logarithmic_error: 0.1250\n",
      "Epoch 97/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9815 - mse: 0.9815 - mae: 0.3918 - root_mean_squared_error: 0.9907 - mean_squared_logarithmic_error: 0.1247\n",
      "Epoch 98/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9839 - mse: 0.9839 - mae: 0.3925 - root_mean_squared_error: 0.9919 - mean_squared_logarithmic_error: 0.1247\n",
      "Epoch 99/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9856 - mse: 0.9856 - mae: 0.3929 - root_mean_squared_error: 0.9928 - mean_squared_logarithmic_error: 0.1256\n",
      "Epoch 100/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9845 - mse: 0.9845 - mae: 0.3922 - root_mean_squared_error: 0.9922 - mean_squared_logarithmic_error: 0.1254\n",
      "Epoch 101/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9825 - mse: 0.9825 - mae: 0.3924 - root_mean_squared_error: 0.9912 - mean_squared_logarithmic_error: 0.1251\n",
      "Epoch 102/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9826 - mse: 0.9826 - mae: 0.3911 - root_mean_squared_error: 0.9913 - mean_squared_logarithmic_error: 0.1248\n",
      "Epoch 103/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9839 - mse: 0.9839 - mae: 0.3932 - root_mean_squared_error: 0.9919 - mean_squared_logarithmic_error: 0.1255\n",
      "Epoch 104/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9770 - mse: 0.9770 - mae: 0.3882 - root_mean_squared_error: 0.9884 - mean_squared_logarithmic_error: 0.1234\n",
      "Epoch 105/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9752 - mse: 0.9752 - mae: 0.3925 - root_mean_squared_error: 0.9875 - mean_squared_logarithmic_error: 0.1249\n",
      "Epoch 106/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9798 - mse: 0.9798 - mae: 0.3905 - root_mean_squared_error: 0.9898 - mean_squared_logarithmic_error: 0.1243\n",
      "Epoch 107/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9778 - mse: 0.9778 - mae: 0.3887 - root_mean_squared_error: 0.9888 - mean_squared_logarithmic_error: 0.1234\n",
      "Epoch 108/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9751 - mse: 0.9751 - mae: 0.3942 - root_mean_squared_error: 0.9875 - mean_squared_logarithmic_error: 0.1255\n",
      "Epoch 109/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9764 - mse: 0.9764 - mae: 0.3904 - root_mean_squared_error: 0.9881 - mean_squared_logarithmic_error: 0.1243\n",
      "Epoch 110/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9775 - mse: 0.9775 - mae: 0.3912 - root_mean_squared_error: 0.9887 - mean_squared_logarithmic_error: 0.1239\n",
      "Epoch 111/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9741 - mse: 0.9741 - mae: 0.3910 - root_mean_squared_error: 0.9870 - mean_squared_logarithmic_error: 0.1242\n",
      "Epoch 112/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9728 - mse: 0.9728 - mae: 0.3914 - root_mean_squared_error: 0.9863 - mean_squared_logarithmic_error: 0.1246\n",
      "Epoch 113/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9729 - mse: 0.9729 - mae: 0.3875 - root_mean_squared_error: 0.9864 - mean_squared_logarithmic_error: 0.1233\n",
      "Epoch 114/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9723 - mse: 0.9723 - mae: 0.3911 - root_mean_squared_error: 0.9860 - mean_squared_logarithmic_error: 0.1246\n",
      "Epoch 115/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9712 - mse: 0.9712 - mae: 0.3931 - root_mean_squared_error: 0.9855 - mean_squared_logarithmic_error: 0.1250\n",
      "Epoch 116/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9719 - mse: 0.9719 - mae: 0.3884 - root_mean_squared_error: 0.9858 - mean_squared_logarithmic_error: 0.1232\n",
      "Epoch 117/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9711 - mse: 0.9711 - mae: 0.3872 - root_mean_squared_error: 0.9854 - mean_squared_logarithmic_error: 0.1228\n",
      "Epoch 118/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9733 - mse: 0.9733 - mae: 0.3935 - root_mean_squared_error: 0.9866 - mean_squared_logarithmic_error: 0.1250\n",
      "Epoch 119/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9703 - mse: 0.9703 - mae: 0.3879 - root_mean_squared_error: 0.9850 - mean_squared_logarithmic_error: 0.1230\n",
      "Epoch 120/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9715 - mse: 0.9715 - mae: 0.3907 - root_mean_squared_error: 0.9856 - mean_squared_logarithmic_error: 0.1241\n",
      "Epoch 121/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9677 - mse: 0.9677 - mae: 0.3896 - root_mean_squared_error: 0.9837 - mean_squared_logarithmic_error: 0.1232\n",
      "Epoch 122/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9691 - mse: 0.9691 - mae: 0.3887 - root_mean_squared_error: 0.9845 - mean_squared_logarithmic_error: 0.1233\n",
      "Epoch 123/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9708 - mse: 0.9708 - mae: 0.3914 - root_mean_squared_error: 0.9853 - mean_squared_logarithmic_error: 0.1241\n",
      "Epoch 124/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9681 - mse: 0.9681 - mae: 0.3898 - root_mean_squared_error: 0.9839 - mean_squared_logarithmic_error: 0.1237\n",
      "Epoch 125/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9695 - mse: 0.9695 - mae: 0.3897 - root_mean_squared_error: 0.9846 - mean_squared_logarithmic_error: 0.1235\n",
      "Epoch 126/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9659 - mse: 0.9659 - mae: 0.3870 - root_mean_squared_error: 0.9828 - mean_squared_logarithmic_error: 0.1229\n",
      "Epoch 127/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9630 - mse: 0.9630 - mae: 0.3914 - root_mean_squared_error: 0.9813 - mean_squared_logarithmic_error: 0.1236\n",
      "Epoch 128/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9669 - mse: 0.9669 - mae: 0.3876 - root_mean_squared_error: 0.9833 - mean_squared_logarithmic_error: 0.1229\n",
      "Epoch 129/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9624 - mse: 0.9624 - mae: 0.3908 - root_mean_squared_error: 0.9810 - mean_squared_logarithmic_error: 0.1233\n",
      "Epoch 130/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9630 - mse: 0.9630 - mae: 0.3898 - root_mean_squared_error: 0.9813 - mean_squared_logarithmic_error: 0.1233\n",
      "Epoch 131/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9630 - mse: 0.9630 - mae: 0.3849 - root_mean_squared_error: 0.9813 - mean_squared_logarithmic_error: 0.1219\n",
      "Epoch 132/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9614 - mse: 0.9614 - mae: 0.3905 - root_mean_squared_error: 0.9805 - mean_squared_logarithmic_error: 0.1231\n",
      "Epoch 133/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9583 - mse: 0.9583 - mae: 0.3873 - root_mean_squared_error: 0.9789 - mean_squared_logarithmic_error: 0.1225\n",
      "Epoch 134/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9640 - mse: 0.9640 - mae: 0.3877 - root_mean_squared_error: 0.9818 - mean_squared_logarithmic_error: 0.1227\n",
      "Epoch 135/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9628 - mse: 0.9628 - mae: 0.3865 - root_mean_squared_error: 0.9812 - mean_squared_logarithmic_error: 0.1220\n",
      "Epoch 136/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9595 - mse: 0.9595 - mae: 0.3884 - root_mean_squared_error: 0.9795 - mean_squared_logarithmic_error: 0.1230\n",
      "Epoch 137/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9597 - mse: 0.9597 - mae: 0.3878 - root_mean_squared_error: 0.9796 - mean_squared_logarithmic_error: 0.1228\n",
      "Epoch 138/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9597 - mse: 0.9597 - mae: 0.3879 - root_mean_squared_error: 0.9796 - mean_squared_logarithmic_error: 0.1227\n",
      "Epoch 139/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9572 - mse: 0.9572 - mae: 0.3874 - root_mean_squared_error: 0.9784 - mean_squared_logarithmic_error: 0.1221\n",
      "Epoch 140/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9579 - mse: 0.9579 - mae: 0.3890 - root_mean_squared_error: 0.9787 - mean_squared_logarithmic_error: 0.1227\n",
      "Epoch 141/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9601 - mse: 0.9601 - mae: 0.3877 - root_mean_squared_error: 0.9798 - mean_squared_logarithmic_error: 0.1222\n",
      "Epoch 142/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9592 - mse: 0.9592 - mae: 0.3876 - root_mean_squared_error: 0.9794 - mean_squared_logarithmic_error: 0.1223\n",
      "Epoch 143/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9581 - mse: 0.9581 - mae: 0.3877 - root_mean_squared_error: 0.9788 - mean_squared_logarithmic_error: 0.1222\n",
      "Epoch 144/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9534 - mse: 0.9534 - mae: 0.3913 - root_mean_squared_error: 0.9764 - mean_squared_logarithmic_error: 0.1234\n",
      "Epoch 145/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9581 - mse: 0.9581 - mae: 0.3847 - root_mean_squared_error: 0.9788 - mean_squared_logarithmic_error: 0.1213\n",
      "Epoch 146/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9555 - mse: 0.9555 - mae: 0.3872 - root_mean_squared_error: 0.9775 - mean_squared_logarithmic_error: 0.1223\n",
      "Epoch 147/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9545 - mse: 0.9545 - mae: 0.3879 - root_mean_squared_error: 0.9770 - mean_squared_logarithmic_error: 0.1222\n",
      "Epoch 148/200\n",
      "462/462 [==============================] - 3s 6ms/step - loss: 0.9527 - mse: 0.9527 - mae: 0.3834 - root_mean_squared_error: 0.9761 - mean_squared_logarithmic_error: 0.1206\n",
      "Epoch 149/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9544 - mse: 0.9544 - mae: 0.3899 - root_mean_squared_error: 0.9769 - mean_squared_logarithmic_error: 0.1232\n",
      "Epoch 150/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9535 - mse: 0.9535 - mae: 0.3863 - root_mean_squared_error: 0.9765 - mean_squared_logarithmic_error: 0.1214\n",
      "Epoch 151/200\n",
      "462/462 [==============================] - 3s 6ms/step - loss: 0.9562 - mse: 0.9562 - mae: 0.3872 - root_mean_squared_error: 0.9779 - mean_squared_logarithmic_error: 0.1222\n",
      "Epoch 152/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9558 - mse: 0.9558 - mae: 0.3871 - root_mean_squared_error: 0.9776 - mean_squared_logarithmic_error: 0.1222\n",
      "Epoch 153/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9507 - mse: 0.9507 - mae: 0.3854 - root_mean_squared_error: 0.9750 - mean_squared_logarithmic_error: 0.1212\n",
      "Epoch 154/200\n",
      "462/462 [==============================] - 3s 6ms/step - loss: 0.9534 - mse: 0.9534 - mae: 0.3864 - root_mean_squared_error: 0.9764 - mean_squared_logarithmic_error: 0.1219\n",
      "Epoch 155/200\n",
      "462/462 [==============================] - 3s 6ms/step - loss: 0.9512 - mse: 0.9512 - mae: 0.3882 - root_mean_squared_error: 0.9753 - mean_squared_logarithmic_error: 0.1219\n",
      "Epoch 156/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9470 - mse: 0.9470 - mae: 0.3852 - root_mean_squared_error: 0.9731 - mean_squared_logarithmic_error: 0.1209\n",
      "Epoch 157/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9513 - mse: 0.9513 - mae: 0.3876 - root_mean_squared_error: 0.9753 - mean_squared_logarithmic_error: 0.1221\n",
      "Epoch 158/200\n",
      "462/462 [==============================] - 3s 6ms/step - loss: 0.9496 - mse: 0.9496 - mae: 0.3854 - root_mean_squared_error: 0.9745 - mean_squared_logarithmic_error: 0.1216\n",
      "Epoch 159/200\n",
      "462/462 [==============================] - 3s 6ms/step - loss: 0.9491 - mse: 0.9491 - mae: 0.3860 - root_mean_squared_error: 0.9742 - mean_squared_logarithmic_error: 0.1212\n",
      "Epoch 160/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9499 - mse: 0.9499 - mae: 0.3832 - root_mean_squared_error: 0.9746 - mean_squared_logarithmic_error: 0.1205\n",
      "Epoch 161/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9467 - mse: 0.9467 - mae: 0.3874 - root_mean_squared_error: 0.9730 - mean_squared_logarithmic_error: 0.1219\n",
      "Epoch 162/200\n",
      "462/462 [==============================] - 2s 4ms/step - loss: 0.9452 - mse: 0.9452 - mae: 0.3857 - root_mean_squared_error: 0.9722 - mean_squared_logarithmic_error: 0.1214\n",
      "Epoch 163/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9498 - mse: 0.9498 - mae: 0.3858 - root_mean_squared_error: 0.9746 - mean_squared_logarithmic_error: 0.1216\n",
      "Epoch 164/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9423 - mse: 0.9423 - mae: 0.3858 - root_mean_squared_error: 0.9707 - mean_squared_logarithmic_error: 0.1210\n",
      "Epoch 165/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9451 - mse: 0.9451 - mae: 0.3857 - root_mean_squared_error: 0.9721 - mean_squared_logarithmic_error: 0.1208\n",
      "Epoch 166/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9488 - mse: 0.9488 - mae: 0.3875 - root_mean_squared_error: 0.9741 - mean_squared_logarithmic_error: 0.1219\n",
      "Epoch 167/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9436 - mse: 0.9436 - mae: 0.3847 - root_mean_squared_error: 0.9714 - mean_squared_logarithmic_error: 0.1211\n",
      "Epoch 168/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9443 - mse: 0.9443 - mae: 0.3862 - root_mean_squared_error: 0.9717 - mean_squared_logarithmic_error: 0.1213\n",
      "Epoch 169/200\n",
      "462/462 [==============================] - 3s 7ms/step - loss: 0.9474 - mse: 0.9474 - mae: 0.3845 - root_mean_squared_error: 0.9733 - mean_squared_logarithmic_error: 0.1209\n",
      "Epoch 170/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9453 - mse: 0.9453 - mae: 0.3839 - root_mean_squared_error: 0.9722 - mean_squared_logarithmic_error: 0.1208\n",
      "Epoch 171/200\n",
      "462/462 [==============================] - 2s 4ms/step - loss: 0.9412 - mse: 0.9412 - mae: 0.3839 - root_mean_squared_error: 0.9702 - mean_squared_logarithmic_error: 0.1202\n",
      "Epoch 172/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9429 - mse: 0.9429 - mae: 0.3854 - root_mean_squared_error: 0.9710 - mean_squared_logarithmic_error: 0.1207\n",
      "Epoch 173/200\n",
      "462/462 [==============================] - 2s 4ms/step - loss: 0.9406 - mse: 0.9406 - mae: 0.3844 - root_mean_squared_error: 0.9698 - mean_squared_logarithmic_error: 0.1207\n",
      "Epoch 174/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "462/462 [==============================] - 2s 4ms/step - loss: 0.9453 - mse: 0.9453 - mae: 0.3828 - root_mean_squared_error: 0.9722 - mean_squared_logarithmic_error: 0.1208\n",
      "Epoch 175/200\n",
      "462/462 [==============================] - 2s 4ms/step - loss: 0.9416 - mse: 0.9416 - mae: 0.3852 - root_mean_squared_error: 0.9704 - mean_squared_logarithmic_error: 0.1207\n",
      "Epoch 176/200\n",
      "462/462 [==============================] - 2s 4ms/step - loss: 0.9417 - mse: 0.9417 - mae: 0.3856 - root_mean_squared_error: 0.9704 - mean_squared_logarithmic_error: 0.1210\n",
      "Epoch 177/200\n",
      "462/462 [==============================] - 2s 4ms/step - loss: 0.9397 - mse: 0.9397 - mae: 0.3826 - root_mean_squared_error: 0.9694 - mean_squared_logarithmic_error: 0.1202\n",
      "Epoch 178/200\n",
      "462/462 [==============================] - 2s 4ms/step - loss: 0.9381 - mse: 0.9381 - mae: 0.3834 - root_mean_squared_error: 0.9685 - mean_squared_logarithmic_error: 0.1202\n",
      "Epoch 179/200\n",
      "462/462 [==============================] - 2s 4ms/step - loss: 0.9365 - mse: 0.9365 - mae: 0.3831 - root_mean_squared_error: 0.9677 - mean_squared_logarithmic_error: 0.1199\n",
      "Epoch 180/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9382 - mse: 0.9382 - mae: 0.3856 - root_mean_squared_error: 0.9686 - mean_squared_logarithmic_error: 0.1211\n",
      "Epoch 181/200\n",
      "462/462 [==============================] - 3s 6ms/step - loss: 0.9383 - mse: 0.9383 - mae: 0.3853 - root_mean_squared_error: 0.9687 - mean_squared_logarithmic_error: 0.1204\n",
      "Epoch 182/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9395 - mse: 0.9395 - mae: 0.3802 - root_mean_squared_error: 0.9693 - mean_squared_logarithmic_error: 0.1197\n",
      "Epoch 183/200\n",
      "462/462 [==============================] - 2s 4ms/step - loss: 0.9371 - mse: 0.9371 - mae: 0.3859 - root_mean_squared_error: 0.9680 - mean_squared_logarithmic_error: 0.1207\n",
      "Epoch 184/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9395 - mse: 0.9395 - mae: 0.3820 - root_mean_squared_error: 0.9693 - mean_squared_logarithmic_error: 0.1199\n",
      "Epoch 185/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9379 - mse: 0.9379 - mae: 0.3828 - root_mean_squared_error: 0.9684 - mean_squared_logarithmic_error: 0.1199\n",
      "Epoch 186/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9377 - mse: 0.9377 - mae: 0.3858 - root_mean_squared_error: 0.9683 - mean_squared_logarithmic_error: 0.1206\n",
      "Epoch 187/200\n",
      "462/462 [==============================] - 2s 4ms/step - loss: 0.9392 - mse: 0.9392 - mae: 0.3833 - root_mean_squared_error: 0.9691 - mean_squared_logarithmic_error: 0.1199\n",
      "Epoch 188/200\n",
      "462/462 [==============================] - 2s 4ms/step - loss: 0.9379 - mse: 0.9379 - mae: 0.3847 - root_mean_squared_error: 0.9685 - mean_squared_logarithmic_error: 0.1207\n",
      "Epoch 189/200\n",
      "462/462 [==============================] - 2s 4ms/step - loss: 0.9335 - mse: 0.9335 - mae: 0.3782 - root_mean_squared_error: 0.9662 - mean_squared_logarithmic_error: 0.1183\n",
      "Epoch 190/200\n",
      "462/462 [==============================] - 2s 4ms/step - loss: 0.9328 - mse: 0.9328 - mae: 0.3842 - root_mean_squared_error: 0.9658 - mean_squared_logarithmic_error: 0.1198\n",
      "Epoch 191/200\n",
      "462/462 [==============================] - 2s 4ms/step - loss: 0.9328 - mse: 0.9328 - mae: 0.3857 - root_mean_squared_error: 0.9658 - mean_squared_logarithmic_error: 0.1210\n",
      "Epoch 192/200\n",
      "462/462 [==============================] - 2s 4ms/step - loss: 0.9333 - mse: 0.9333 - mae: 0.3811 - root_mean_squared_error: 0.9661 - mean_squared_logarithmic_error: 0.1193\n",
      "Epoch 193/200\n",
      "462/462 [==============================] - 2s 4ms/step - loss: 0.9316 - mse: 0.9316 - mae: 0.3838 - root_mean_squared_error: 0.9652 - mean_squared_logarithmic_error: 0.1198\n",
      "Epoch 194/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9338 - mse: 0.9338 - mae: 0.3829 - root_mean_squared_error: 0.9663 - mean_squared_logarithmic_error: 0.1197\n",
      "Epoch 195/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9299 - mse: 0.9299 - mae: 0.3830 - root_mean_squared_error: 0.9643 - mean_squared_logarithmic_error: 0.1194\n",
      "Epoch 196/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9291 - mse: 0.9291 - mae: 0.3827 - root_mean_squared_error: 0.9639 - mean_squared_logarithmic_error: 0.1200\n",
      "Epoch 197/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9267 - mse: 0.9267 - mae: 0.3828 - root_mean_squared_error: 0.9626 - mean_squared_logarithmic_error: 0.1195\n",
      "Epoch 198/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9331 - mse: 0.9331 - mae: 0.3826 - root_mean_squared_error: 0.9660 - mean_squared_logarithmic_error: 0.1200\n",
      "Epoch 199/200\n",
      "462/462 [==============================] - 2s 4ms/step - loss: 0.9307 - mse: 0.9307 - mae: 0.3808 - root_mean_squared_error: 0.9647 - mean_squared_logarithmic_error: 0.1190\n",
      "Epoch 200/200\n",
      "462/462 [==============================] - 2s 5ms/step - loss: 0.9273 - mse: 0.9273 - mae: 0.3848 - root_mean_squared_error: 0.9630 - mean_squared_logarithmic_error: 0.1207\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model on training data.\n",
    "import datetime\n",
    "log_dir = '/home/bavanya/Desktop/tensorboard/' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "history = model.fit(train_x, train_y, epochs = 200, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 3750), started 3:48:36 ago. (Use '!kill 3750' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7d1ff0a1a277d764\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7d1ff0a1a277d764\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir '/home/bavanya/Desktop/tensorboard/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 1s 2ms/step - loss: 1.0397 - mse: 1.0397 - mae: 0.3770 - root_mean_squared_error: 1.0196 - mean_squared_logarithmic_error: 0.1277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0396785736083984,\n",
       " 1.0396785736083984,\n",
       " 0.37704965472221375,\n",
       " 1.0196462869644165,\n",
       " 0.12771815061569214]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(test_x, test_y)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
