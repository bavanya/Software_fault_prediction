{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MID 3\n",
    "### Taking ant1.3 as training data.\n",
    "### ant1.4 as testing data.\n",
    "### Min max scaling done to few columns: ['wmc', 'dit', 'noc', 'cbo', 'rfc', 'lcom', 'ca', 'ce', 'npm', 'lcom3', 'loc', 'dam', 'moa', 'mfa', 'cam', 'ic', 'cbm', 'amc', 'max_cc', 'avg_cc']\n",
    "### Oversampling and smote methods used to increase size of training data.\n",
    "### CNN model used, model type is 2 as per the BTP documentation spreadsheet.\n",
    "### np.rint() used on predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from keras.layers import Dense,Dropout,Conv2D,Conv1D,Flatten,MaxPool2D\n",
    "import tensorflow as tf\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data. \n",
    "train_data_path = \"/home/bavanya/Desktop/6thSem/BTP/regression_PROMISE_dataset/datasets/ant-1.3.csv\"\n",
    "test_data_path = \"/home/bavanya/Desktop/6thSem/BTP/regression_PROMISE_dataset/datasets/ant-1.4.csv\"\n",
    "train_data_name = \"ant-1.3\"\n",
    "test_data_name = \"ant-1.4\"\n",
    "ant_1_3 = pd.read_csv(train_data_path)\n",
    "ant_1_4 = pd.read_csv(test_data_path)\n",
    "files = [\"/home/bavanya/Desktop/6thSem/BTP/regression_PROMISE_dataset/datasets/ant-1.3.csv\", \"/home/bavanya/Desktop/6thSem/BTP/regression_PROMISE_dataset/datasets/ant-1.4.csv\"]\n",
    "combined_data = pd.concat(map(pd.read_csv, files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Min Max Scaling.\n",
    "scaler = MinMaxScaler()\n",
    "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
    "cols_to_norm = ['wmc', 'dit', 'noc', 'cbo', 'rfc', 'lcom', 'ca', 'ce', 'npm', 'lcom3', 'loc', 'dam', 'moa', 'mfa', 'cam', 'ic', 'cbm', 'amc', 'max_cc', 'avg_cc']\n",
    "combined_data[cols_to_norm] = MinMaxScaler().fit_transform(combined_data[cols_to_norm])\n",
    "\n",
    "ant_1_3_scaled = combined_data[combined_data['version'] == 1.3] \n",
    "ant_1_4_scaled = combined_data[combined_data['version'] == 1.4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting training and test data.\n",
    "X_train = ant_1_3_scaled[cols_to_norm]\n",
    "X_train = np.array(X_train)\n",
    "Y_train = ant_1_3['bug']\n",
    "\n",
    "X_test = ant_1_4_scaled[cols_to_norm]\n",
    "X_test = np.array(X_test)\n",
    "Y_test = ant_1_4['bug']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cols_to_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying over sampling and SMOTE to training data for augmentation.\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_train, Y_train = ros.fit_resample(X_train, Y_train)\n",
    "\n",
    "smt = SMOTE()\n",
    "X_train, Y_train = smt.fit_resample(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wmc</th>\n",
       "      <th>dit</th>\n",
       "      <th>noc</th>\n",
       "      <th>cbo</th>\n",
       "      <th>rfc</th>\n",
       "      <th>lcom</th>\n",
       "      <th>ca</th>\n",
       "      <th>ce</th>\n",
       "      <th>npm</th>\n",
       "      <th>lcom3</th>\n",
       "      <th>loc</th>\n",
       "      <th>dam</th>\n",
       "      <th>moa</th>\n",
       "      <th>mfa</th>\n",
       "      <th>cam</th>\n",
       "      <th>ic</th>\n",
       "      <th>cbm</th>\n",
       "      <th>amc</th>\n",
       "      <th>max_cc</th>\n",
       "      <th>avg_cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.102941</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.011856</td>\n",
       "      <td>0.014815</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.073529</td>\n",
       "      <td>0.362500</td>\n",
       "      <td>0.180119</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.885057</td>\n",
       "      <td>0.232323</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.165951</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.209085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.163265</td>\n",
       "      <td>0.020033</td>\n",
       "      <td>0.029630</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.417582</td>\n",
       "      <td>0.117191</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080979</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.269903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.038961</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.045918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026448</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.083267</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.109529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.155844</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.188776</td>\n",
       "      <td>0.013083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.429293</td>\n",
       "      <td>0.141359</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115693</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.232742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.077922</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.062016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.100881</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.136898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.110294</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.075634</td>\n",
       "      <td>0.014815</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.419643</td>\n",
       "      <td>0.538076</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.180272</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.251110</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.171759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0.103896</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.051471</td>\n",
       "      <td>0.173469</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.285454</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.917647</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.367494</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.266962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>0.220779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.139706</td>\n",
       "      <td>0.372449</td>\n",
       "      <td>0.045789</td>\n",
       "      <td>0.096296</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.073529</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.228910</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170455</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135355</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.164285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>0.220779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.139706</td>\n",
       "      <td>0.372449</td>\n",
       "      <td>0.045789</td>\n",
       "      <td>0.096296</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.073529</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.228910</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170455</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135355</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.164285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>0.077922</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.073529</td>\n",
       "      <td>0.168367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.073529</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.090287</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.151321</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.164285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          wmc  dit    noc       cbo       rfc      lcom        ca        ce  \\\n",
       "0    0.142857  0.6  0.050  0.102941  0.214286  0.011856  0.014815  0.428571   \n",
       "1    0.181818  0.0  0.025  0.058824  0.163265  0.020033  0.029630  0.142857   \n",
       "2    0.038961  0.2  0.000  0.007353  0.045918  0.000000  0.000000  0.035714   \n",
       "3    0.155844  0.4  0.000  0.088235  0.188776  0.013083  0.000000  0.428571   \n",
       "4    0.077922  0.4  0.000  0.029412  0.107143  0.000409  0.000000  0.142857   \n",
       "..        ...  ...    ...       ...       ...       ...       ...       ...   \n",
       "415  0.285714  0.6  0.025  0.110294  0.530612  0.075634  0.014815  0.464286   \n",
       "416  0.103896  0.6  0.000  0.051471  0.173469  0.002453  0.000000  0.250000   \n",
       "417  0.220779  0.0  0.000  0.139706  0.372449  0.045789  0.096296  0.250000   \n",
       "418  0.220779  0.0  0.000  0.139706  0.372449  0.045789  0.096296  0.250000   \n",
       "419  0.077922  0.4  0.000  0.073529  0.168367  0.000000  0.022222  0.285714   \n",
       "\n",
       "          npm     lcom3       loc  dam       moa       mfa       cam    ic  \\\n",
       "0    0.073529  0.362500  0.180119  1.0  0.111111  0.885057  0.232323  0.75   \n",
       "1    0.176471  0.417582  0.117191  1.0  0.000000  0.000000  0.307692  0.00   \n",
       "2    0.014706  0.000000  0.026448  1.0  0.111111  0.714286  0.666667  0.25   \n",
       "3    0.176471  0.429293  0.141359  1.0  0.111111  0.770833  0.458333  0.00   \n",
       "4    0.088235  0.350000  0.062016  1.0  0.000000  0.880952  0.416667  0.50   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   ...   \n",
       "415  0.117647  0.419643  0.538076  1.0  0.000000  0.795918  0.180272  0.75   \n",
       "416  0.117647  0.380952  0.285454  1.0  0.000000  0.917647  0.437500  0.50   \n",
       "417  0.073529  0.421875  0.228910  1.0  0.111111  0.000000  0.170455  0.00   \n",
       "418  0.073529  0.421875  0.228910  1.0  0.111111  0.000000  0.170455  0.00   \n",
       "419  0.073529  0.233333  0.090287  1.0  0.111111  0.880952  0.333333  0.50   \n",
       "\n",
       "          cbm       amc    max_cc    avg_cc  \n",
       "0    0.363636  0.165951  0.085714  0.209085  \n",
       "1    0.000000  0.080979  0.171429  0.269903  \n",
       "2    0.090909  0.083267  0.028571  0.109529  \n",
       "3    0.000000  0.115693  0.085714  0.232742  \n",
       "4    0.181818  0.100881  0.028571  0.136898  \n",
       "..        ...       ...       ...       ...  \n",
       "415  0.272727  0.251110  0.085714  0.171759  \n",
       "416  0.181818  0.367494  0.085714  0.266962  \n",
       "417  0.000000  0.135355  0.057143  0.164285  \n",
       "418  0.000000  0.135355  0.057143  0.164285  \n",
       "419  0.363636  0.151321  0.057143  0.164285  \n",
       "\n",
       "[420 rows x 20 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating X_train dataframe after SMOTE\n",
    "X_train = pd.DataFrame(X_train, columns=cols_to_norm)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     bug\n",
       "0      0\n",
       "1      2\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "..   ...\n",
       "415    3\n",
       "416    3\n",
       "417    3\n",
       "418    3\n",
       "419    3\n",
       "\n",
       "[420 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating Y_train dataframe after SMOTE\n",
    "Y_train = pd.DataFrame(Y_train, columns=['bug'])\n",
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wmc</th>\n",
       "      <th>dit</th>\n",
       "      <th>noc</th>\n",
       "      <th>cbo</th>\n",
       "      <th>rfc</th>\n",
       "      <th>lcom</th>\n",
       "      <th>ca</th>\n",
       "      <th>ce</th>\n",
       "      <th>npm</th>\n",
       "      <th>lcom3</th>\n",
       "      <th>loc</th>\n",
       "      <th>dam</th>\n",
       "      <th>moa</th>\n",
       "      <th>mfa</th>\n",
       "      <th>cam</th>\n",
       "      <th>ic</th>\n",
       "      <th>cbm</th>\n",
       "      <th>amc</th>\n",
       "      <th>max_cc</th>\n",
       "      <th>avg_cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.209184</td>\n",
       "      <td>0.013491</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.380342</td>\n",
       "      <td>0.175559</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.124214</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.258157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064935</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.066176</td>\n",
       "      <td>0.219388</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.073529</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.125855</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.257486</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.131428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.168831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>0.018806</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.050616</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034735</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.126368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.103896</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.051471</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.102941</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.120839</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.917647</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.150721</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.225891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.402597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>0.331633</td>\n",
       "      <td>0.099346</td>\n",
       "      <td>0.029630</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.363333</td>\n",
       "      <td>0.340629</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.182796</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.108629</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.190784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.064935</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.051471</td>\n",
       "      <td>0.096939</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>0.029630</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.068855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.138351</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.131428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.220779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.110294</td>\n",
       "      <td>0.336735</td>\n",
       "      <td>0.036795</td>\n",
       "      <td>0.029630</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>0.287278</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197917</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.172373</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.396221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.298701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.227941</td>\n",
       "      <td>0.418367</td>\n",
       "      <td>0.082175</td>\n",
       "      <td>0.162963</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.446970</td>\n",
       "      <td>0.498404</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.219724</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.378561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.161765</td>\n",
       "      <td>0.438776</td>\n",
       "      <td>0.006132</td>\n",
       "      <td>0.059259</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.364286</td>\n",
       "      <td>0.404469</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.373390</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.761689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.051948</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.022059</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.026904</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.064852</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.287498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          wmc  dit    noc       cbo       rfc      lcom        ca        ce  \\\n",
       "0    0.181818  0.4  0.000  0.058824  0.209184  0.013491  0.007407  0.285714   \n",
       "1    0.064935  0.4  0.000  0.066176  0.219388  0.000000  0.000000  0.321429   \n",
       "2    0.168831  0.0  0.025  0.058824  0.102041  0.018806  0.044444  0.071429   \n",
       "3    0.103896  0.6  0.000  0.051471  0.178571  0.001635  0.000000  0.250000   \n",
       "4    0.402597  0.0  0.000  0.044118  0.331633  0.099346  0.029630  0.071429   \n",
       "..        ...  ...    ...       ...       ...       ...       ...       ...   \n",
       "173  0.064935  0.4  0.000  0.051471  0.096939  0.001635  0.029630  0.142857   \n",
       "174  0.220779  0.0  0.075  0.110294  0.336735  0.036795  0.029630  0.428571   \n",
       "175  0.298701  0.0  0.000  0.227941  0.418367  0.082175  0.162963  0.964286   \n",
       "176  0.142857  0.0  0.200  0.161765  0.438776  0.006132  0.059259  0.500000   \n",
       "177  0.051948  0.2  0.000  0.022059  0.081633  0.000000  0.000000  0.107143   \n",
       "\n",
       "          npm     lcom3       loc       dam       moa       mfa       cam  \\\n",
       "0    0.147059  0.380342  0.175559  1.000000  0.222222  0.740000  0.357143   \n",
       "1    0.073529  0.333333  0.125855  1.000000  0.000000  0.902439  0.533333   \n",
       "2    0.117647  0.333333  0.050616  1.000000  0.000000  0.000000  0.615385   \n",
       "3    0.102941  0.357143  0.120839  1.000000  0.000000  0.917647  0.468750   \n",
       "4    0.441176  0.363333  0.340629  1.000000  0.000000  0.000000  0.182796   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "173  0.058824  0.375000  0.068855  0.000000  0.000000  0.902439  0.400000   \n",
       "174  0.088235  0.395833  0.287278  1.000000  0.222222  0.000000  0.197917   \n",
       "175  0.250000  0.446970  0.498404  0.444444  0.000000  0.000000  0.318182   \n",
       "176  0.058824  0.364286  0.404469  1.000000  0.777778  0.000000  0.266667   \n",
       "177  0.058824  0.166667  0.026904  1.000000  0.000000  0.842105  0.875000   \n",
       "\n",
       "       ic       cbm       amc    max_cc    avg_cc  \n",
       "0    0.25  0.090909  0.124214  0.114286  0.258157  \n",
       "1    0.50  0.272727  0.257486  0.028571  0.131428  \n",
       "2    0.00  0.000000  0.034735  0.028571  0.126368  \n",
       "3    0.75  0.272727  0.150721  0.142857  0.225891  \n",
       "4    0.25  0.090909  0.108629  0.114286  0.190784  \n",
       "..    ...       ...       ...       ...       ...  \n",
       "173  0.25  0.090909  0.138351  0.028571  0.131428  \n",
       "174  0.00  0.000000  0.172373  0.400000  0.396221  \n",
       "175  0.00  0.000000  0.219724  0.685714  0.378561  \n",
       "176  0.00  0.000000  0.373390  0.628571  0.761689  \n",
       "177  0.25  0.090909  0.064852  0.142857  0.287498  \n",
       "\n",
       "[178 rows x 20 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating X_test dataframe after SMOTE\n",
    "X_test = pd.DataFrame(X_test, columns=cols_to_norm)\n",
    "X_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     bug\n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "..   ...\n",
       "173    0\n",
       "174    0\n",
       "175    0\n",
       "176    1\n",
       "177    0\n",
       "\n",
       "[178 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating Y_test dataframe after SMOTE\n",
    "Y_test = pd.DataFrame(Y_test, columns=['bug'])\n",
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the rows and columns size in our data\n",
    "img_rows, img_cols = 1,len(cols_to_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data for the model.\n",
    "X_train_matrix = X_train.values\n",
    "X_test_matrix = X_test.values\n",
    "Y_train_matrix = Y_train.values\n",
    "Y_test_matrix = Y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data for the model.\n",
    "Ytrainseries = Y_train['bug']\n",
    "Ytestseries = Y_test['bug']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data for the model.\n",
    "X_train1 = X_train_matrix.reshape(X_train_matrix.shape[0], img_rows, img_cols, 1)\n",
    "X_test1 = X_test_matrix.reshape(X_test_matrix.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the model\n",
    "model = Sequential()\n",
    "\n",
    "#add model layers\n",
    "model.add(Conv2D(64, kernel_size=1, activation='relu',input_shape=input_shape))\n",
    "model.add(Conv2D(32, kernel_size=1, activation='relu'))\n",
    "model.add(Conv2D(16, kernel_size=1, activation='relu'))\n",
    "    \n",
    "    \n",
    "#model.add(MaxPool2D(pool_size=(1,8)))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "#compile model using mse as the loss function\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse', 'mae', tf.keras.metrics.RootMeanSquaredError(), tf.keras.metrics.MeanSquaredLogarithmicError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 1, 20, 64)         128       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 1, 20, 32)         2080      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 1, 20, 16)         528       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 2568      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 5,313\n",
      "Trainable params: 5,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3.3477 - mse: 3.3477 - mae: 1.4705 - root_mean_squared_error: 1.8297 - mean_squared_logarithmic_error: 0.8250\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.0264 - mse: 3.0264 - mae: 1.4124 - root_mean_squared_error: 1.7397 - mean_squared_logarithmic_error: 0.6814\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.6661 - mse: 2.6661 - mae: 1.3392 - root_mean_squared_error: 1.6328 - mean_squared_logarithmic_error: 0.5470\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.2652 - mse: 2.2652 - mae: 1.2441 - root_mean_squared_error: 1.5050 - mean_squared_logarithmic_error: 0.4256\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.8300 - mse: 1.8300 - mae: 1.1233 - root_mean_squared_error: 1.3528 - mean_squared_logarithmic_error: 0.3282\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.4084 - mse: 1.4084 - mae: 0.9948 - root_mean_squared_error: 1.1867 - mean_squared_logarithmic_error: 0.2644\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.2073 - mse: 1.2073 - mae: 0.9938 - root_mean_squared_error: 1.0988 - mean_squared_logarithmic_error: 0.2664\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.2586 - mse: 1.2586 - mae: 0.9918 - root_mean_squared_error: 1.1219 - mean_squared_logarithmic_error: 0.3067\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.3164 - mse: 1.3164 - mae: 0.9911 - root_mean_squared_error: 1.1473 - mean_squared_logarithmic_error: 0.3235\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.2411 - mse: 1.2411 - mae: 0.9889 - root_mean_squared_error: 1.1140 - mean_squared_logarithmic_error: 0.3023\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1810 - mse: 1.1810 - mae: 0.9866 - root_mean_squared_error: 1.0867 - mean_squared_logarithmic_error: 0.2750\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1900 - mse: 1.1900 - mae: 0.9888 - root_mean_squared_error: 1.0909 - mean_squared_logarithmic_error: 0.2618\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1982 - mse: 1.1982 - mae: 0.9866 - root_mean_squared_error: 1.0946 - mean_squared_logarithmic_error: 0.2589\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1848 - mse: 1.1848 - mae: 0.9844 - root_mean_squared_error: 1.0885 - mean_squared_logarithmic_error: 0.2597\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1698 - mse: 1.1698 - mae: 0.9840 - root_mean_squared_error: 1.0816 - mean_squared_logarithmic_error: 0.2632\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1591 - mse: 1.1591 - mae: 0.9806 - root_mean_squared_error: 1.0766 - mean_squared_logarithmic_error: 0.2674\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1545 - mse: 1.1545 - mae: 0.9783 - root_mean_squared_error: 1.0745 - mean_squared_logarithmic_error: 0.2705\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1533 - mse: 1.1533 - mae: 0.9768 - root_mean_squared_error: 1.0739 - mean_squared_logarithmic_error: 0.2727\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1473 - mse: 1.1473 - mae: 0.9747 - root_mean_squared_error: 1.0711 - mean_squared_logarithmic_error: 0.2712\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1385 - mse: 1.1385 - mae: 0.9721 - root_mean_squared_error: 1.0670 - mean_squared_logarithmic_error: 0.2664\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1341 - mse: 1.1341 - mae: 0.9706 - root_mean_squared_error: 1.0649 - mean_squared_logarithmic_error: 0.2612\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1293 - mse: 1.1293 - mae: 0.9684 - root_mean_squared_error: 1.0627 - mean_squared_logarithmic_error: 0.2585\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1224 - mse: 1.1224 - mae: 0.9656 - root_mean_squared_error: 1.0594 - mean_squared_logarithmic_error: 0.2575\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1169 - mse: 1.1169 - mae: 0.9632 - root_mean_squared_error: 1.0568 - mean_squared_logarithmic_error: 0.2579\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1099 - mse: 1.1099 - mae: 0.9606 - root_mean_squared_error: 1.0535 - mean_squared_logarithmic_error: 0.2563\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1033 - mse: 1.1033 - mae: 0.9571 - root_mean_squared_error: 1.0504 - mean_squared_logarithmic_error: 0.2529\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0965 - mse: 1.0965 - mae: 0.9541 - root_mean_squared_error: 1.0471 - mean_squared_logarithmic_error: 0.2513\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0870 - mse: 1.0870 - mae: 0.9501 - root_mean_squared_error: 1.0426 - mean_squared_logarithmic_error: 0.2511\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0814 - mse: 1.0814 - mae: 0.9464 - root_mean_squared_error: 1.0399 - mean_squared_logarithmic_error: 0.2552\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0751 - mse: 1.0751 - mae: 0.9422 - root_mean_squared_error: 1.0369 - mean_squared_logarithmic_error: 0.2561\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0643 - mse: 1.0643 - mae: 0.9385 - root_mean_squared_error: 1.0316 - mean_squared_logarithmic_error: 0.2512\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0561 - mse: 1.0561 - mae: 0.9350 - root_mean_squared_error: 1.0277 - mean_squared_logarithmic_error: 0.2451\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0488 - mse: 1.0488 - mae: 0.9303 - root_mean_squared_error: 1.0241 - mean_squared_logarithmic_error: 0.2401\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0397 - mse: 1.0397 - mae: 0.9255 - root_mean_squared_error: 1.0197 - mean_squared_logarithmic_error: 0.2379\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0305 - mse: 1.0305 - mae: 0.9208 - root_mean_squared_error: 1.0152 - mean_squared_logarithmic_error: 0.2386\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0191 - mse: 1.0191 - mae: 0.9148 - root_mean_squared_error: 1.0095 - mean_squared_logarithmic_error: 0.2363\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0096 - mse: 1.0096 - mae: 0.9091 - root_mean_squared_error: 1.0048 - mean_squared_logarithmic_error: 0.2330\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9984 - mse: 0.9984 - mae: 0.9026 - root_mean_squared_error: 0.9992 - mean_squared_logarithmic_error: 0.2313\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9871 - mse: 0.9871 - mae: 0.8949 - root_mean_squared_error: 0.9935 - mean_squared_logarithmic_error: 0.2307\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9778 - mse: 0.9778 - mae: 0.8886 - root_mean_squared_error: 0.9888 - mean_squared_logarithmic_error: 0.2296\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9668 - mse: 0.9668 - mae: 0.8823 - root_mean_squared_error: 0.9833 - mean_squared_logarithmic_error: 0.2260\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9557 - mse: 0.9557 - mae: 0.8751 - root_mean_squared_error: 0.9776 - mean_squared_logarithmic_error: 0.2234\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9451 - mse: 0.9451 - mae: 0.8679 - root_mean_squared_error: 0.9722 - mean_squared_logarithmic_error: 0.2210\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9348 - mse: 0.9348 - mae: 0.8620 - root_mean_squared_error: 0.9669 - mean_squared_logarithmic_error: 0.2164\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9260 - mse: 0.9260 - mae: 0.8557 - root_mean_squared_error: 0.9623 - mean_squared_logarithmic_error: 0.2131\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9163 - mse: 0.9163 - mae: 0.8489 - root_mean_squared_error: 0.9572 - mean_squared_logarithmic_error: 0.2088\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9057 - mse: 0.9057 - mae: 0.8406 - root_mean_squared_error: 0.9517 - mean_squared_logarithmic_error: 0.2048\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8996 - mse: 0.8996 - mae: 0.8326 - root_mean_squared_error: 0.9485 - mean_squared_logarithmic_error: 0.2081\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8872 - mse: 0.8872 - mae: 0.8219 - root_mean_squared_error: 0.9419 - mean_squared_logarithmic_error: 0.2077\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8731 - mse: 0.8731 - mae: 0.8136 - root_mean_squared_error: 0.9344 - mean_squared_logarithmic_error: 0.2030\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8647 - mse: 0.8647 - mae: 0.8084 - root_mean_squared_error: 0.9299 - mean_squared_logarithmic_error: 0.1981\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8535 - mse: 0.8535 - mae: 0.7993 - root_mean_squared_error: 0.9239 - mean_squared_logarithmic_error: 0.1944\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8443 - mse: 0.8443 - mae: 0.7894 - root_mean_squared_error: 0.9189 - mean_squared_logarithmic_error: 0.1955\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8358 - mse: 0.8358 - mae: 0.7793 - root_mean_squared_error: 0.9142 - mean_squared_logarithmic_error: 0.1959\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8291 - mse: 0.8291 - mae: 0.7706 - root_mean_squared_error: 0.9105 - mean_squared_logarithmic_error: 0.1954\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8182 - mse: 0.8182 - mae: 0.7650 - root_mean_squared_error: 0.9045 - mean_squared_logarithmic_error: 0.1907\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8089 - mse: 0.8089 - mae: 0.7646 - root_mean_squared_error: 0.8994 - mean_squared_logarithmic_error: 0.1849\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8030 - mse: 0.8030 - mae: 0.7612 - root_mean_squared_error: 0.8961 - mean_squared_logarithmic_error: 0.1830\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7946 - mse: 0.7946 - mae: 0.7509 - root_mean_squared_error: 0.8914 - mean_squared_logarithmic_error: 0.1833\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7891 - mse: 0.7891 - mae: 0.7429 - root_mean_squared_error: 0.8883 - mean_squared_logarithmic_error: 0.1848\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7855 - mse: 0.7855 - mae: 0.7396 - root_mean_squared_error: 0.8863 - mean_squared_logarithmic_error: 0.1850\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7819 - mse: 0.7819 - mae: 0.7434 - root_mean_squared_error: 0.8843 - mean_squared_logarithmic_error: 0.1776\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7796 - mse: 0.7796 - mae: 0.7474 - root_mean_squared_error: 0.8830 - mean_squared_logarithmic_error: 0.1732\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7665 - mse: 0.7665 - mae: 0.7312 - root_mean_squared_error: 0.8755 - mean_squared_logarithmic_error: 0.1753\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7665 - mse: 0.7665 - mae: 0.7256 - root_mean_squared_error: 0.8755 - mean_squared_logarithmic_error: 0.1801\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7625 - mse: 0.7625 - mae: 0.7235 - root_mean_squared_error: 0.8732 - mean_squared_logarithmic_error: 0.1778\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7575 - mse: 0.7575 - mae: 0.7275 - root_mean_squared_error: 0.8704 - mean_squared_logarithmic_error: 0.1706\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7533 - mse: 0.7533 - mae: 0.7223 - root_mean_squared_error: 0.8679 - mean_squared_logarithmic_error: 0.1709\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7470 - mse: 0.7470 - mae: 0.7131 - root_mean_squared_error: 0.8643 - mean_squared_logarithmic_error: 0.1729\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7436 - mse: 0.7436 - mae: 0.7116 - root_mean_squared_error: 0.8623 - mean_squared_logarithmic_error: 0.1700\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7400 - mse: 0.7400 - mae: 0.7114 - root_mean_squared_error: 0.8602 - mean_squared_logarithmic_error: 0.1683\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7373 - mse: 0.7373 - mae: 0.7050 - root_mean_squared_error: 0.8587 - mean_squared_logarithmic_error: 0.1704\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7334 - mse: 0.7334 - mae: 0.7054 - root_mean_squared_error: 0.8564 - mean_squared_logarithmic_error: 0.1679\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7287 - mse: 0.7287 - mae: 0.7024 - root_mean_squared_error: 0.8536 - mean_squared_logarithmic_error: 0.1663\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7868 - mse: 0.7868 - mae: 0.7415 - root_mean_squared_error: 0.8870 - mean_squared_logarithmic_error: 0.19 - 0s 6ms/step - loss: 0.7304 - mse: 0.7304 - mae: 0.6950 - root_mean_squared_error: 0.8547 - mean_squared_logarithmic_error: 0.1720\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7294 - mse: 0.7294 - mae: 0.6981 - root_mean_squared_error: 0.8540 - mean_squared_logarithmic_error: 0.1677\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7220 - mse: 0.7220 - mae: 0.7071 - root_mean_squared_error: 0.8497 - mean_squared_logarithmic_error: 0.1610\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7107 - mse: 0.7107 - mae: 0.6892 - root_mean_squared_error: 0.8430 - mean_squared_logarithmic_error: 0.1646\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7190 - mse: 0.7190 - mae: 0.6826 - root_mean_squared_error: 0.8479 - mean_squared_logarithmic_error: 0.1712\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7116 - mse: 0.7116 - mae: 0.6834 - root_mean_squared_error: 0.8435 - mean_squared_logarithmic_error: 0.1677\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7006 - mse: 0.7006 - mae: 0.6820 - root_mean_squared_error: 0.8370 - mean_squared_logarithmic_error: 0.1636\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6910 - mse: 0.6910 - mae: 0.6810 - root_mean_squared_error: 0.8313 - mean_squared_logarithmic_error: 0.1593\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6850 - mse: 0.6850 - mae: 0.6731 - root_mean_squared_error: 0.8277 - mean_squared_logarithmic_error: 0.1595\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6779 - mse: 0.6779 - mae: 0.6729 - root_mean_squared_error: 0.8233 - mean_squared_logarithmic_error: 0.1549\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6755 - mse: 0.6755 - mae: 0.6723 - root_mean_squared_error: 0.8219 - mean_squared_logarithmic_error: 0.1536\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6657 - mse: 0.6657 - mae: 0.6659 - root_mean_squared_error: 0.8159 - mean_squared_logarithmic_error: 0.1526\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6576 - mse: 0.6576 - mae: 0.6613 - root_mean_squared_error: 0.8109 - mean_squared_logarithmic_error: 0.1517\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6518 - mse: 0.6518 - mae: 0.6450 - root_mean_squared_error: 0.8074 - mean_squared_logarithmic_error: 0.1548\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6428 - mse: 0.6428 - mae: 0.6380 - root_mean_squared_error: 0.8018 - mean_squared_logarithmic_error: 0.1542\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6428 - mse: 0.6428 - mae: 0.6515 - root_mean_squared_error: 0.8017 - mean_squared_logarithmic_error: 0.1486\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6347 - mse: 0.6347 - mae: 0.6391 - root_mean_squared_error: 0.7967 - mean_squared_logarithmic_error: 0.1485\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6223 - mse: 0.6223 - mae: 0.6221 - root_mean_squared_error: 0.7888 - mean_squared_logarithmic_error: 0.1508\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6152 - mse: 0.6152 - mae: 0.6222 - root_mean_squared_error: 0.7844 - mean_squared_logarithmic_error: 0.1472\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6062 - mse: 0.6062 - mae: 0.6121 - root_mean_squared_error: 0.7786 - mean_squared_logarithmic_error: 0.1473\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6013 - mse: 0.6013 - mae: 0.6020 - root_mean_squared_error: 0.7754 - mean_squared_logarithmic_error: 0.1489\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5946 - mse: 0.5946 - mae: 0.6115 - root_mean_squared_error: 0.7711 - mean_squared_logarithmic_error: 0.1410\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5816 - mse: 0.5816 - mae: 0.6062 - root_mean_squared_error: 0.7626 - mean_squared_logarithmic_error: 0.1392\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5798 - mse: 0.5798 - mae: 0.5800 - root_mean_squared_error: 0.7614 - mean_squared_logarithmic_error: 0.1470\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5632 - mse: 0.5632 - mae: 0.5742 - root_mean_squared_error: 0.7505 - mean_squared_logarithmic_error: 0.1430\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5649 - mse: 0.5649 - mae: 0.6003 - root_mean_squared_error: 0.7516 - mean_squared_logarithmic_error: 0.1339\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model on training data.\n",
    "history = model.fit(X_train1, Y_train_matrix, epochs = 100, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95741487],\n",
       "       [1.8154376 ],\n",
       "       [0.62886   ],\n",
       "       [1.4323324 ],\n",
       "       [1.3270772 ],\n",
       "       [0.9934691 ],\n",
       "       [1.6132008 ],\n",
       "       [0.        ],\n",
       "       [0.82455075],\n",
       "       [2.2223775 ],\n",
       "       [1.3640704 ],\n",
       "       [2.3311577 ],\n",
       "       [0.7706549 ],\n",
       "       [1.3643173 ],\n",
       "       [1.4656059 ],\n",
       "       [0.        ],\n",
       "       [2.2422698 ],\n",
       "       [0.30854362],\n",
       "       [0.        ],\n",
       "       [0.7750977 ],\n",
       "       [0.7510083 ],\n",
       "       [0.3601112 ],\n",
       "       [0.3732196 ],\n",
       "       [1.6824895 ],\n",
       "       [2.3395653 ],\n",
       "       [1.5563829 ],\n",
       "       [0.80490327],\n",
       "       [0.6004784 ],\n",
       "       [0.9173728 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [1.0680909 ],\n",
       "       [0.5708803 ],\n",
       "       [0.        ],\n",
       "       [1.2409664 ],\n",
       "       [0.        ],\n",
       "       [0.8786179 ],\n",
       "       [0.        ],\n",
       "       [1.3930678 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [1.9242854 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.9272046 ],\n",
       "       [1.8502474 ],\n",
       "       [2.283653  ],\n",
       "       [0.62511337],\n",
       "       [0.14302424],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.24432924],\n",
       "       [0.        ],\n",
       "       [1.3520678 ],\n",
       "       [0.92609406],\n",
       "       [0.        ],\n",
       "       [0.10474491],\n",
       "       [0.89490783],\n",
       "       [0.        ],\n",
       "       [1.5464559 ],\n",
       "       [0.        ],\n",
       "       [0.9151151 ],\n",
       "       [0.        ],\n",
       "       [1.2629406 ],\n",
       "       [1.8877957 ],\n",
       "       [0.        ],\n",
       "       [0.01290658],\n",
       "       [1.5441521 ],\n",
       "       [0.        ],\n",
       "       [1.6226585 ],\n",
       "       [0.        ],\n",
       "       [1.630516  ],\n",
       "       [1.7728724 ],\n",
       "       [1.324297  ],\n",
       "       [0.        ],\n",
       "       [1.3528615 ],\n",
       "       [0.37157562],\n",
       "       [3.281457  ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.5657085 ],\n",
       "       [1.4550442 ],\n",
       "       [0.05502978],\n",
       "       [0.09583053],\n",
       "       [0.        ],\n",
       "       [1.2722799 ],\n",
       "       [1.3633157 ],\n",
       "       [1.3078706 ],\n",
       "       [1.9099665 ],\n",
       "       [0.29562515],\n",
       "       [1.5966125 ],\n",
       "       [1.4009495 ],\n",
       "       [0.8812127 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [1.5898834 ],\n",
       "       [0.        ],\n",
       "       [1.0436133 ],\n",
       "       [0.        ],\n",
       "       [0.40431622],\n",
       "       [0.4713038 ],\n",
       "       [0.        ],\n",
       "       [2.2027676 ],\n",
       "       [0.576751  ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [2.5839207 ],\n",
       "       [0.        ],\n",
       "       [1.0322393 ],\n",
       "       [0.        ],\n",
       "       [0.8493053 ],\n",
       "       [0.22111478],\n",
       "       [1.1073642 ],\n",
       "       [2.276315  ],\n",
       "       [2.0705621 ],\n",
       "       [0.        ],\n",
       "       [0.39154598],\n",
       "       [0.        ],\n",
       "       [0.15699062],\n",
       "       [1.318186  ],\n",
       "       [2.002329  ],\n",
       "       [0.        ],\n",
       "       [1.0689807 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [1.353945  ],\n",
       "       [2.0877411 ],\n",
       "       [1.2045876 ],\n",
       "       [0.77765524],\n",
       "       [0.        ],\n",
       "       [0.87131333],\n",
       "       [0.74218714],\n",
       "       [1.1449056 ],\n",
       "       [0.5532054 ],\n",
       "       [0.        ],\n",
       "       [1.2630295 ],\n",
       "       [1.9517869 ],\n",
       "       [0.17203674],\n",
       "       [1.3151853 ],\n",
       "       [1.0348061 ],\n",
       "       [0.        ],\n",
       "       [1.5287467 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [1.2475147 ],\n",
       "       [1.4869342 ],\n",
       "       [0.56321645],\n",
       "       [0.74021566],\n",
       "       [0.06832227],\n",
       "       [0.15222785],\n",
       "       [0.        ],\n",
       "       [1.6653904 ],\n",
       "       [0.16203019],\n",
       "       [0.10981068],\n",
       "       [1.0170214 ],\n",
       "       [1.4923415 ],\n",
       "       [1.9976757 ],\n",
       "       [1.8253896 ],\n",
       "       [0.48111627],\n",
       "       [0.74282336],\n",
       "       [1.8352022 ],\n",
       "       [1.2935083 ],\n",
       "       [0.97722507],\n",
       "       [1.2001687 ],\n",
       "       [0.69670284],\n",
       "       [0.        ],\n",
       "       [0.59949434],\n",
       "       [0.        ],\n",
       "       [0.5678102 ],\n",
       "       [0.01313242],\n",
       "       [0.        ],\n",
       "       [2.1343806 ],\n",
       "       [1.6180936 ],\n",
       "       [0.7986436 ],\n",
       "       [0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the predictions.\n",
    "predictions_y = model.predict(X_test1)\n",
    "predictions_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rounding off the predictions to nearest\n",
    "#integer as count of bugs is an integer.\n",
    "predictions_y_round = np.rint(predictions_y)\n",
    "predictions_y_round "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the number of predictions.\n",
    "predictions_y_round.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([139.], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the sum of all the predictions obtained to used while obtaining FPA\n",
    "s = 0\n",
    "for  t in range(predictions_y_round.shape[0]):\n",
    "    s+=predictions_y_round[t]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4846415], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtaining the value of FPA metric for the model\n",
    "Fpa = 0\n",
    "for  t in range(predictions_y_round.shape[0]):\n",
    "        x = 0\n",
    "        for j in range( predictions_y_round.shape[0]-t+1, predictions_y_round.shape[0]):\n",
    "               x = x + predictions_y_round[j]\n",
    "        \n",
    "        x = (x/s)/predictions_y_round.shape[0]\n",
    "        Fpa = Fpa + x\n",
    "Fpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4930281], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtaining the value of CLC metric for the model\n",
    "previous_obtained = predictions_y_round[predictions_y_round.shape[0] - 1]/s\n",
    "\n",
    "CLC = 0\n",
    "for i in range(predictions_y_round.shape[0]):\n",
    "    if(i==0):\n",
    "        CLC += 0 + previous_obtained\n",
    "    else:\n",
    "        additional = (predictions_y_round[predictions_y_round.shape[0] - 1 - i])/s\n",
    "        CLC += 2*previous_obtained + additional\n",
    "        previous_obtained += additional\n",
    "        \n",
    "CLC/=(2*predictions_y_round.shape[0])\n",
    "CLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step - loss: 1.1203 - mse: 1.1203 - mae: 0.7957 - root_mean_squared_error: 1.0584 - mean_squared_logarithmic_error: 0.3892\n",
      "dict_keys(['loss', 'mse', 'mae', 'root_mean_squared_error', 'mean_squared_logarithmic_error'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['loss',\n",
       " 'mse',\n",
       " 'mae',\n",
       " 'root_mean_squared_error',\n",
       " 'mean_squared_logarithmic_error']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting direct metric results using the metrics given to model.\n",
    "score = model.evaluate(X_test1, Y_test_matrix)\n",
    "print(history.history.keys())\n",
    "model.test_on_batch(X_test1, Y_test_matrix)\n",
    "model.metrics_names\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[2], score[2]*100))\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[3], score[3]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bavanya/Downloads/deb_packages/home/bavanya/Desktop/venv_python/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/bavanya/Downloads/deb_packages/home/bavanya/Desktop/venv_python/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: /home/bavanya/Desktop/6thSem/BTP/regression_PROMISE_dataset/saved_models/ant1.3_ant1.4_model2/ant1.3_ant1.4_model2_1/assets\n"
     ]
    }
   ],
   "source": [
    "# Saving the model\n",
    "model_id = 3\n",
    "path_to_save = '/home/bavanya/Desktop/6thSem/BTP/regression_PROMISE_dataset/saved_models/ant1.3_ant1.4_model2/ant1.3_ant1.4_model2_1'\n",
    "model.save(path_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the results to csv file.\n",
    "heading = ['model_id', 'train_data_name', 'test_data_name'] + model.metrics_names + ['fpa', 'clc']\n",
    "score = [model_id, train_data_name, test_data_name] + score + [float(Fpa) , float(CLC)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_id',\n",
       " 'train_data_name',\n",
       " 'test_data_name',\n",
       " 'loss',\n",
       " 'mse',\n",
       " 'mae',\n",
       " 'root_mean_squared_error',\n",
       " 'mean_squared_logarithmic_error',\n",
       " 'fpa',\n",
       " 'clc']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 'ant-1.3',\n",
       " 'ant-1.4',\n",
       " 1.120253562927246,\n",
       " 1.120253562927246,\n",
       " 0.7956892848014832,\n",
       " 1.0584203004837036,\n",
       " 0.38921767473220825,\n",
       " 0.48464149236679077,\n",
       " 0.49302810430526733]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the results to csv file.\n",
    "with open(path_to_save + '_metric_results.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(heading)\n",
    "    writer.writerow(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model and to make sure that the model is saved properly.\n",
    "model_loaded = load_model(path_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
