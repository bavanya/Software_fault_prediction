{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MID 1\n",
    "### Taking ant1.3 as training data.\n",
    "### ant1.4 as testing data.\n",
    "### Min max scaling done to few columns: ['wmc', 'dit', 'noc', 'cbo', 'rfc', 'lcom', 'ca', 'ce', 'npm', 'lcom3', 'loc', 'dam', 'moa', 'mfa', 'cam', 'ic', 'cbm', 'amc', 'max_cc', 'avg_cc']\n",
    "### Oversampling and smote methods used to increase size of training data.\n",
    "### LSTM model used, model type is 1 as per the BTP documentation spreadsheet.\n",
    "### np.rint() used on predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense\n",
    "import tensorflow as tf\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data. \n",
    "train_data_path = \"/home/bavanya/Desktop/6thSem/BTP/regression_PROMISE_dataset/datasets/ant-1.3.csv\"\n",
    "test_data_path = \"/home/bavanya/Desktop/6thSem/BTP/regression_PROMISE_dataset/datasets/ant-1.4.csv\"\n",
    "train_data_name = \"ant-1.3\"\n",
    "test_data_name = \"ant-1.4\"\n",
    "ant_1_3 = pd.read_csv(train_data_path)\n",
    "ant_1_4 = pd.read_csv(test_data_path)\n",
    "files = [\"/home/bavanya/Desktop/6thSem/BTP/regression_PROMISE_dataset/datasets/ant-1.3.csv\", \"/home/bavanya/Desktop/6thSem/BTP/regression_PROMISE_dataset/datasets/ant-1.4.csv\"]\n",
    "combined_data = pd.concat(map(pd.read_csv, files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Min Max Scaling.\n",
    "scaler = MinMaxScaler()\n",
    "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
    "cols_to_norm = ['wmc', 'dit', 'noc', 'cbo', 'rfc', 'lcom', 'ca', 'ce', 'npm', 'lcom3', 'loc', 'dam', 'moa', 'mfa', 'cam', 'ic', 'cbm', 'amc', 'max_cc', 'avg_cc']\n",
    "combined_data[cols_to_norm] = MinMaxScaler().fit_transform(combined_data[cols_to_norm])\n",
    "\n",
    "ant_1_3_scaled = combined_data[combined_data['version'] == 1.3] \n",
    "ant_1_4_scaled = combined_data[combined_data['version'] == 1.4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting training and test data.\n",
    "X_train = ant_1_3_scaled[cols_to_norm]\n",
    "X_train = np.array(X_train)\n",
    "Y_train = ant_1_3['bug']\n",
    "\n",
    "X_test = ant_1_4_scaled[cols_to_norm]\n",
    "X_test = np.array(X_test)\n",
    "Y_test = ant_1_4['bug']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying over sampling and SMOTE to training data for augmentation.\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_train, Y_train = ros.fit_resample(X_train, Y_train)\n",
    "\n",
    "smt = SMOTE()\n",
    "X_train, Y_train = smt.fit_resample(X_train, Y_train)\n",
    "\n",
    "train_x = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "test_x = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.14285714, 0.6       , 0.05      , ..., 0.16595094,\n",
       "         0.08571429, 0.20908494]],\n",
       "\n",
       "       [[0.18181818, 0.        , 0.025     , ..., 0.08097907,\n",
       "         0.17142857, 0.26990307]],\n",
       "\n",
       "       [[0.03896104, 0.2       , 0.        , ..., 0.08326661,\n",
       "         0.02857143, 0.1095285 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.22077922, 0.        , 0.        , ..., 0.13535534,\n",
       "         0.05714286, 0.16428454]],\n",
       "\n",
       "       [[0.22077922, 0.        , 0.        , ..., 0.13535534,\n",
       "         0.05714286, 0.16428454]],\n",
       "\n",
       "       [[0.07792208, 0.4       , 0.        , ..., 0.15132106,\n",
       "         0.05714286, 0.16428454]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      2\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "415    3\n",
       "416    3\n",
       "417    3\n",
       "418    3\n",
       "419    3\n",
       "Name: bug, Length: 420, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 3, 0, 0, 0, 2, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = Y_train.to_numpy()\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.18181818, 0.4       , 0.        , ..., 0.12421366,\n",
       "         0.11428571, 0.25815673]],\n",
       "\n",
       "       [[0.06493506, 0.4       , 0.        , ..., 0.25748599,\n",
       "         0.02857143, 0.13142763]],\n",
       "\n",
       "       [[0.16883117, 0.        , 0.025     , ..., 0.03473548,\n",
       "         0.02857143, 0.12636767]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.2987013 , 0.        , 0.        , ..., 0.2197236 ,\n",
       "         0.68571429, 0.37856087]],\n",
       "\n",
       "       [[0.14285714, 0.        , 0.2       , ..., 0.37338962,\n",
       "         0.62857143, 0.76168885]],\n",
       "\n",
       "       [[0.05194805, 0.2       , 0.        , ..., 0.06485188,\n",
       "         0.14285714, 0.28749795]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "173    0\n",
       "174    0\n",
       "175    0\n",
       "176    1\n",
       "177    0\n",
       "Name: bug, Length: 178, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 3, 0, 0, 0, 0, 3, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = Y_test.to_numpy()\n",
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designing and initializing the model.\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape = (1,20), dropout = 0.2, return_sequences=True))\n",
    "model.add(LSTM(80, dropout = 0.2, return_sequences=True))\n",
    "model.add(LSTM(60, dropout = 0.2, return_sequences=False))\n",
    "model.add(Dense(1, activation = 'relu'))\n",
    "model.compile(loss = 'mse' , optimizer = 'adam' , metrics = ['mse', 'mae', tf.keras.metrics.RootMeanSquaredError(), tf.keras.metrics.MeanSquaredLogarithmicError()] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 1, 100)            48400     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 1, 80)             57920     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 60)                33840     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 140,221\n",
      "Trainable params: 140,221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.4786 - mse: 3.4786 - mae: 1.4965 - root_mean_squared_error: 1.8651 - mean_squared_logarithmic_error: 0.8912\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.4041 - mse: 3.4041 - mae: 1.4840 - root_mean_squared_error: 1.8450 - mean_squared_logarithmic_error: 0.8530\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.3003 - mse: 3.3003 - mae: 1.4656 - root_mean_squared_error: 1.8167 - mean_squared_logarithmic_error: 0.8026\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.1549 - mse: 3.1549 - mae: 1.4394 - root_mean_squared_error: 1.7762 - mean_squared_logarithmic_error: 0.7369\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 2.9651 - mse: 2.9651 - mae: 1.4034 - root_mean_squared_error: 1.7219 - mean_squared_logarithmic_error: 0.6579\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 2.6651 - mse: 2.6651 - mae: 1.3385 - root_mean_squared_error: 1.6325 - mean_squared_logarithmic_error: 0.5488\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 2.2581 - mse: 2.2581 - mae: 1.2408 - root_mean_squared_error: 1.5027 - mean_squared_logarithmic_error: 0.4296\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.7667 - mse: 1.7667 - mae: 1.1085 - root_mean_squared_error: 1.3292 - mean_squared_logarithmic_error: 0.3236\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.3056 - mse: 1.3056 - mae: 0.9856 - root_mean_squared_error: 1.1426 - mean_squared_logarithmic_error: 0.2587\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.3320 - mse: 1.3320 - mae: 0.9858 - root_mean_squared_error: 1.1541 - mean_squared_logarithmic_error: 0.3026\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.3542 - mse: 1.3542 - mae: 0.9768 - root_mean_squared_error: 1.1637 - mean_squared_logarithmic_error: 0.3064\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2617 - mse: 1.2617 - mae: 0.9810 - root_mean_squared_error: 1.1233 - mean_squared_logarithmic_error: 0.2902\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2066 - mse: 1.2066 - mae: 0.9766 - root_mean_squared_error: 1.0985 - mean_squared_logarithmic_error: 0.2665\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2184 - mse: 1.2184 - mae: 0.9725 - root_mean_squared_error: 1.1038 - mean_squared_logarithmic_error: 0.2599\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2091 - mse: 1.2091 - mae: 0.9776 - root_mean_squared_error: 1.0996 - mean_squared_logarithmic_error: 0.2605\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1664 - mse: 1.1664 - mae: 0.9595 - root_mean_squared_error: 1.0800 - mean_squared_logarithmic_error: 0.2568\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1653 - mse: 1.1653 - mae: 0.9553 - root_mean_squared_error: 1.0795 - mean_squared_logarithmic_error: 0.2638\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.2147 - mse: 1.2147 - mae: 0.9743 - root_mean_squared_error: 1.1021 - mean_squared_logarithmic_error: 0.2753\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1834 - mse: 1.1834 - mae: 0.9636 - root_mean_squared_error: 1.0878 - mean_squared_logarithmic_error: 0.2691\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1923 - mse: 1.1923 - mae: 0.9724 - root_mean_squared_error: 1.0919 - mean_squared_logarithmic_error: 0.2728\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.2069 - mse: 1.2069 - mae: 0.9685 - root_mean_squared_error: 1.0986 - mean_squared_logarithmic_error: 0.2760\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1469 - mse: 1.1469 - mae: 0.9519 - root_mean_squared_error: 1.0710 - mean_squared_logarithmic_error: 0.2639\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1657 - mse: 1.1657 - mae: 0.9685 - root_mean_squared_error: 1.0797 - mean_squared_logarithmic_error: 0.2604\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.2047 - mse: 1.2047 - mae: 0.9747 - root_mean_squared_error: 1.0976 - mean_squared_logarithmic_error: 0.2652\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1320 - mse: 1.1320 - mae: 0.9591 - root_mean_squared_error: 1.0640 - mean_squared_logarithmic_error: 0.2521\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1086 - mse: 1.1086 - mae: 0.9328 - root_mean_squared_error: 1.0529 - mean_squared_logarithmic_error: 0.2511\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1516 - mse: 1.1516 - mae: 0.9466 - root_mean_squared_error: 1.0731 - mean_squared_logarithmic_error: 0.2604\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1039 - mse: 1.1039 - mae: 0.9368 - root_mean_squared_error: 1.0507 - mean_squared_logarithmic_error: 0.2551\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0953 - mse: 1.0953 - mae: 0.9270 - root_mean_squared_error: 1.0465 - mean_squared_logarithmic_error: 0.2479\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0830 - mse: 1.0830 - mae: 0.9252 - root_mean_squared_error: 1.0407 - mean_squared_logarithmic_error: 0.2456\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1021 - mse: 1.1021 - mae: 0.9244 - root_mean_squared_error: 1.0498 - mean_squared_logarithmic_error: 0.2510\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1574 - mse: 1.1574 - mae: 0.9506 - root_mean_squared_error: 1.0758 - mean_squared_logarithmic_error: 0.2655\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1103 - mse: 1.1103 - mae: 0.9242 - root_mean_squared_error: 1.0537 - mean_squared_logarithmic_error: 0.2562\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0809 - mse: 1.0809 - mae: 0.9212 - root_mean_squared_error: 1.0397 - mean_squared_logarithmic_error: 0.2430\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0796 - mse: 1.0796 - mae: 0.9213 - root_mean_squared_error: 1.0390 - mean_squared_logarithmic_error: 0.2390\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0637 - mse: 1.0637 - mae: 0.9158 - root_mean_squared_error: 1.0314 - mean_squared_logarithmic_error: 0.2410\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0904 - mse: 1.0904 - mae: 0.9274 - root_mean_squared_error: 1.0442 - mean_squared_logarithmic_error: 0.2461\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0284 - mse: 1.0284 - mae: 0.8999 - root_mean_squared_error: 1.0141 - mean_squared_logarithmic_error: 0.2354\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0494 - mse: 1.0494 - mae: 0.9023 - root_mean_squared_error: 1.0244 - mean_squared_logarithmic_error: 0.2402\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0644 - mse: 1.0644 - mae: 0.9133 - root_mean_squared_error: 1.0317 - mean_squared_logarithmic_error: 0.2457\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0365 - mse: 1.0365 - mae: 0.8886 - root_mean_squared_error: 1.0181 - mean_squared_logarithmic_error: 0.2395\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0163 - mse: 1.0163 - mae: 0.8804 - root_mean_squared_error: 1.0081 - mean_squared_logarithmic_error: 0.2312\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0537 - mse: 1.0537 - mae: 0.9042 - root_mean_squared_error: 1.0265 - mean_squared_logarithmic_error: 0.2410\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0536 - mse: 1.0536 - mae: 0.8963 - root_mean_squared_error: 1.0264 - mean_squared_logarithmic_error: 0.2442\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9789 - mse: 0.9789 - mae: 0.8614 - root_mean_squared_error: 0.9894 - mean_squared_logarithmic_error: 0.2292\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0462 - mse: 1.0462 - mae: 0.8814 - root_mean_squared_error: 1.0229 - mean_squared_logarithmic_error: 0.2359\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9998 - mse: 0.9998 - mae: 0.8692 - root_mean_squared_error: 0.9999 - mean_squared_logarithmic_error: 0.2271\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0060 - mse: 1.0060 - mae: 0.8694 - root_mean_squared_error: 1.0030 - mean_squared_logarithmic_error: 0.2291\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9147 - mse: 0.9147 - mae: 0.8317 - root_mean_squared_error: 0.9564 - mean_squared_logarithmic_error: 0.2139\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0461 - mse: 1.0461 - mae: 0.8834 - root_mean_squared_error: 1.0228 - mean_squared_logarithmic_error: 0.2309\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9688 - mse: 0.9688 - mae: 0.8441 - root_mean_squared_error: 0.9843 - mean_squared_logarithmic_error: 0.2160\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0466 - mse: 1.0466 - mae: 0.8932 - root_mean_squared_error: 1.0231 - mean_squared_logarithmic_error: 0.2331\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9524 - mse: 0.9524 - mae: 0.8467 - root_mean_squared_error: 0.9759 - mean_squared_logarithmic_error: 0.2168\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9555 - mse: 0.9555 - mae: 0.8390 - root_mean_squared_error: 0.9775 - mean_squared_logarithmic_error: 0.2166\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9567 - mse: 0.9567 - mae: 0.8401 - root_mean_squared_error: 0.9781 - mean_squared_logarithmic_error: 0.2155\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0197 - mse: 1.0197 - mae: 0.8758 - root_mean_squared_error: 1.0098 - mean_squared_logarithmic_error: 0.2212\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9850 - mse: 0.9850 - mae: 0.8571 - root_mean_squared_error: 0.9925 - mean_squared_logarithmic_error: 0.2243\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0545 - mse: 1.0545 - mae: 0.8649 - root_mean_squared_error: 1.0269 - mean_squared_logarithmic_error: 0.2379\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9957 - mse: 0.9957 - mae: 0.8416 - root_mean_squared_error: 0.9978 - mean_squared_logarithmic_error: 0.2281\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9600 - mse: 0.9600 - mae: 0.8233 - root_mean_squared_error: 0.9798 - mean_squared_logarithmic_error: 0.2251\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0275 - mse: 1.0275 - mae: 0.8717 - root_mean_squared_error: 1.0136 - mean_squared_logarithmic_error: 0.2263\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9143 - mse: 0.9143 - mae: 0.8168 - root_mean_squared_error: 0.9562 - mean_squared_logarithmic_error: 0.2083\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9886 - mse: 0.9886 - mae: 0.8456 - root_mean_squared_error: 0.9943 - mean_squared_logarithmic_error: 0.2127\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9445 - mse: 0.9445 - mae: 0.8288 - root_mean_squared_error: 0.9719 - mean_squared_logarithmic_error: 0.2142\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9698 - mse: 0.9698 - mae: 0.8422 - root_mean_squared_error: 0.9848 - mean_squared_logarithmic_error: 0.2258\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9585 - mse: 0.9585 - mae: 0.8266 - root_mean_squared_error: 0.9790 - mean_squared_logarithmic_error: 0.2185\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9596 - mse: 0.9596 - mae: 0.8373 - root_mean_squared_error: 0.9796 - mean_squared_logarithmic_error: 0.2218\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9410 - mse: 0.9410 - mae: 0.8434 - root_mean_squared_error: 0.9700 - mean_squared_logarithmic_error: 0.2135\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9187 - mse: 0.9187 - mae: 0.8230 - root_mean_squared_error: 0.9585 - mean_squared_logarithmic_error: 0.2104\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9159 - mse: 0.9159 - mae: 0.8125 - root_mean_squared_error: 0.9570 - mean_squared_logarithmic_error: 0.2106\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9429 - mse: 0.9429 - mae: 0.8307 - root_mean_squared_error: 0.9710 - mean_squared_logarithmic_error: 0.2157\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9192 - mse: 0.9192 - mae: 0.8135 - root_mean_squared_error: 0.9588 - mean_squared_logarithmic_error: 0.2154\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9465 - mse: 0.9465 - mae: 0.8260 - root_mean_squared_error: 0.9729 - mean_squared_logarithmic_error: 0.2109\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9084 - mse: 0.9084 - mae: 0.8140 - root_mean_squared_error: 0.9531 - mean_squared_logarithmic_error: 0.2066\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9389 - mse: 0.9389 - mae: 0.8146 - root_mean_squared_error: 0.9690 - mean_squared_logarithmic_error: 0.2127\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9289 - mse: 0.9289 - mae: 0.8084 - root_mean_squared_error: 0.9638 - mean_squared_logarithmic_error: 0.2134\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8995 - mse: 0.8995 - mae: 0.8108 - root_mean_squared_error: 0.9484 - mean_squared_logarithmic_error: 0.2098\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9191 - mse: 0.9191 - mae: 0.8245 - root_mean_squared_error: 0.9587 - mean_squared_logarithmic_error: 0.2114\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9350 - mse: 0.9350 - mae: 0.8216 - root_mean_squared_error: 0.9670 - mean_squared_logarithmic_error: 0.2134\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9589 - mse: 0.9589 - mae: 0.8343 - root_mean_squared_error: 0.9793 - mean_squared_logarithmic_error: 0.2192\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9626 - mse: 0.9626 - mae: 0.8239 - root_mean_squared_error: 0.9811 - mean_squared_logarithmic_error: 0.2077\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9700 - mse: 0.9700 - mae: 0.8485 - root_mean_squared_error: 0.9849 - mean_squared_logarithmic_error: 0.2147\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9672 - mse: 0.9672 - mae: 0.8353 - root_mean_squared_error: 0.9834 - mean_squared_logarithmic_error: 0.2199\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9326 - mse: 0.9326 - mae: 0.8157 - root_mean_squared_error: 0.9657 - mean_squared_logarithmic_error: 0.2192\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9802 - mse: 0.9802 - mae: 0.8475 - root_mean_squared_error: 0.9901 - mean_squared_logarithmic_error: 0.2165\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9712 - mse: 0.9712 - mae: 0.8374 - root_mean_squared_error: 0.9855 - mean_squared_logarithmic_error: 0.2174\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8559 - mse: 0.8559 - mae: 0.8010 - root_mean_squared_error: 0.9251 - mean_squared_logarithmic_error: 0.1924\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9186 - mse: 0.9186 - mae: 0.8287 - root_mean_squared_error: 0.9584 - mean_squared_logarithmic_error: 0.2033\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9210 - mse: 0.9210 - mae: 0.8025 - root_mean_squared_error: 0.9597 - mean_squared_logarithmic_error: 0.2148\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9395 - mse: 0.9395 - mae: 0.8075 - root_mean_squared_error: 0.9693 - mean_squared_logarithmic_error: 0.2220\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9479 - mse: 0.9479 - mae: 0.8046 - root_mean_squared_error: 0.9736 - mean_squared_logarithmic_error: 0.2203\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9177 - mse: 0.9177 - mae: 0.8119 - root_mean_squared_error: 0.9580 - mean_squared_logarithmic_error: 0.2074\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9393 - mse: 0.9393 - mae: 0.8218 - root_mean_squared_error: 0.9692 - mean_squared_logarithmic_error: 0.2153\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9384 - mse: 0.9384 - mae: 0.8178 - root_mean_squared_error: 0.9687 - mean_squared_logarithmic_error: 0.2160\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9365 - mse: 0.9365 - mae: 0.8297 - root_mean_squared_error: 0.9677 - mean_squared_logarithmic_error: 0.2154\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9627 - mse: 0.9627 - mae: 0.8234 - root_mean_squared_error: 0.9812 - mean_squared_logarithmic_error: 0.2184\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9234 - mse: 0.9234 - mae: 0.8151 - root_mean_squared_error: 0.9609 - mean_squared_logarithmic_error: 0.2122\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9471 - mse: 0.9471 - mae: 0.8191 - root_mean_squared_error: 0.9732 - mean_squared_logarithmic_error: 0.2147\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8897 - mse: 0.8897 - mae: 0.7968 - root_mean_squared_error: 0.9432 - mean_squared_logarithmic_error: 0.1989\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9225 - mse: 0.9225 - mae: 0.8163 - root_mean_squared_error: 0.9604 - mean_squared_logarithmic_error: 0.2131\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model on training data.\n",
    "history = model.fit(train_x, train_y, epochs = 100, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.36469   ],\n",
       "       [1.8954377 ],\n",
       "       [0.96784693],\n",
       "       [1.7399871 ],\n",
       "       [1.824862  ],\n",
       "       [1.5361497 ],\n",
       "       [1.2400578 ],\n",
       "       [0.01020331],\n",
       "       [0.99321526],\n",
       "       [2.0420282 ],\n",
       "       [1.4222519 ],\n",
       "       [2.2585347 ],\n",
       "       [1.0876822 ],\n",
       "       [1.3847476 ],\n",
       "       [1.7614616 ],\n",
       "       [0.39533663],\n",
       "       [2.205994  ],\n",
       "       [0.6751531 ],\n",
       "       [0.2871837 ],\n",
       "       [1.0671968 ],\n",
       "       [1.2301543 ],\n",
       "       [0.78297335],\n",
       "       [0.98001105],\n",
       "       [1.5546768 ],\n",
       "       [1.829542  ],\n",
       "       [1.5134819 ],\n",
       "       [1.3980005 ],\n",
       "       [1.0140859 ],\n",
       "       [1.4698241 ],\n",
       "       [0.03218498],\n",
       "       [0.        ],\n",
       "       [0.62057525],\n",
       "       [0.55270606],\n",
       "       [1.4737132 ],\n",
       "       [0.7245477 ],\n",
       "       [0.17742874],\n",
       "       [1.2143254 ],\n",
       "       [0.10347813],\n",
       "       [1.0687355 ],\n",
       "       [1.0509539 ],\n",
       "       [1.3815622 ],\n",
       "       [0.        ],\n",
       "       [0.03810829],\n",
       "       [2.2186868 ],\n",
       "       [0.13993487],\n",
       "       [0.45986843],\n",
       "       [1.7394943 ],\n",
       "       [1.752877  ],\n",
       "       [2.4800756 ],\n",
       "       [0.8857091 ],\n",
       "       [1.1356711 ],\n",
       "       [0.15239921],\n",
       "       [0.5848356 ],\n",
       "       [0.        ],\n",
       "       [0.728321  ],\n",
       "       [0.8948183 ],\n",
       "       [1.9122509 ],\n",
       "       [1.4029342 ],\n",
       "       [0.        ],\n",
       "       [0.61447364],\n",
       "       [1.0290236 ],\n",
       "       [0.77664584],\n",
       "       [1.527217  ],\n",
       "       [0.39109367],\n",
       "       [2.081069  ],\n",
       "       [1.0905392 ],\n",
       "       [1.6312313 ],\n",
       "       [2.085529  ],\n",
       "       [0.9411687 ],\n",
       "       [0.40597117],\n",
       "       [1.6104956 ],\n",
       "       [0.2796827 ],\n",
       "       [1.4310559 ],\n",
       "       [0.96762544],\n",
       "       [1.6115837 ],\n",
       "       [1.7529504 ],\n",
       "       [1.7718353 ],\n",
       "       [0.7657002 ],\n",
       "       [1.7457494 ],\n",
       "       [1.3627148 ],\n",
       "       [2.7036166 ],\n",
       "       [0.        ],\n",
       "       [0.91473204],\n",
       "       [1.0617514 ],\n",
       "       [1.9509985 ],\n",
       "       [0.7450865 ],\n",
       "       [0.35125542],\n",
       "       [1.0718905 ],\n",
       "       [1.5561862 ],\n",
       "       [1.571203  ],\n",
       "       [1.4100194 ],\n",
       "       [2.1984594 ],\n",
       "       [1.4313409 ],\n",
       "       [1.797631  ],\n",
       "       [1.8175676 ],\n",
       "       [1.260808  ],\n",
       "       [0.        ],\n",
       "       [0.54563636],\n",
       "       [1.5500016 ],\n",
       "       [0.5057313 ],\n",
       "       [1.1675503 ],\n",
       "       [0.        ],\n",
       "       [0.8943528 ],\n",
       "       [1.0758687 ],\n",
       "       [0.7522581 ],\n",
       "       [2.2026672 ],\n",
       "       [0.99868995],\n",
       "       [0.        ],\n",
       "       [1.0019549 ],\n",
       "       [2.349692  ],\n",
       "       [0.8978484 ],\n",
       "       [1.4582155 ],\n",
       "       [0.621775  ],\n",
       "       [1.1395102 ],\n",
       "       [1.1402497 ],\n",
       "       [1.0207808 ],\n",
       "       [2.0875218 ],\n",
       "       [2.023645  ],\n",
       "       [0.19265485],\n",
       "       [1.0490818 ],\n",
       "       [0.83242804],\n",
       "       [0.8432718 ],\n",
       "       [1.4427018 ],\n",
       "       [1.8594778 ],\n",
       "       [0.08118784],\n",
       "       [1.2530501 ],\n",
       "       [1.0775673 ],\n",
       "       [0.93820757],\n",
       "       [1.2376617 ],\n",
       "       [2.0279884 ],\n",
       "       [1.2784096 ],\n",
       "       [1.2438343 ],\n",
       "       [0.08247222],\n",
       "       [1.4200165 ],\n",
       "       [1.6045771 ],\n",
       "       [1.0468292 ],\n",
       "       [0.857523  ],\n",
       "       [1.0474089 ],\n",
       "       [1.4336654 ],\n",
       "       [1.3639528 ],\n",
       "       [0.8087688 ],\n",
       "       [1.4854238 ],\n",
       "       [1.0668194 ],\n",
       "       [0.6443388 ],\n",
       "       [1.4232712 ],\n",
       "       [0.4816388 ],\n",
       "       [0.19153914],\n",
       "       [1.3690759 ],\n",
       "       [1.5342615 ],\n",
       "       [1.0571313 ],\n",
       "       [1.0545722 ],\n",
       "       [1.2784559 ],\n",
       "       [1.8061585 ],\n",
       "       [0.37612253],\n",
       "       [1.3962665 ],\n",
       "       [1.3028632 ],\n",
       "       [0.5891008 ],\n",
       "       [1.527298  ],\n",
       "       [1.0156229 ],\n",
       "       [2.0579689 ],\n",
       "       [2.0441055 ],\n",
       "       [0.98852557],\n",
       "       [1.1165099 ],\n",
       "       [1.4540052 ],\n",
       "       [1.391165  ],\n",
       "       [1.4900115 ],\n",
       "       [1.3662975 ],\n",
       "       [1.2978526 ],\n",
       "       [0.53389305],\n",
       "       [1.0355217 ],\n",
       "       [0.49946046],\n",
       "       [1.067473  ],\n",
       "       [0.7068127 ],\n",
       "       [1.1577771 ],\n",
       "       [1.561789  ],\n",
       "       [1.8517268 ],\n",
       "       [1.0075213 ],\n",
       "       [0.59718144]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the predictions.\n",
    "predictions_y = model.predict(test_x)\n",
    "predictions_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rounding off the predictions to nearest\n",
    "#integer as count of bugs is an integer.\n",
    "predictions_y_round = np.rint(predictions_y)\n",
    "predictions_y_round "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the number of predictions.\n",
    "predictions_y_round.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([197.], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the sum of all the predictions obtained to used while obtaining FPA\n",
    "s = 0\n",
    "for  t in range(predictions_y_round.shape[0]):\n",
    "    s+=predictions_y_round[t]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4891348], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtaining the value of FPA metric for the model\n",
    "Fpa = 0\n",
    "for  t in range(predictions_y_round.shape[0]):\n",
    "        x = 0\n",
    "        for j in range( predictions_y_round.shape[0]-t+1, predictions_y_round.shape[0]):\n",
    "               x = x + predictions_y_round[j]\n",
    "        \n",
    "        x = (x/s)/predictions_y_round.shape[0]\n",
    "        Fpa = Fpa + x\n",
    "Fpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49753347], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtaining the value of CLC metric for the model\n",
    "previous_obtained = predictions_y_round[predictions_y_round.shape[0] - 1]/s\n",
    "\n",
    "CLC = 0\n",
    "for i in range(predictions_y_round.shape[0]):\n",
    "    if(i==0):\n",
    "        CLC += 0 + previous_obtained\n",
    "    else:\n",
    "        additional = (predictions_y_round[predictions_y_round.shape[0] - 1 - i])/s\n",
    "        CLC += 2*previous_obtained + additional\n",
    "        previous_obtained += additional\n",
    "        \n",
    "CLC/=(2*predictions_y_round.shape[0])\n",
    "CLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step - loss: 1.3541 - mse: 1.3541 - mae: 0.9932 - root_mean_squared_error: 1.1637 - mean_squared_logarithmic_error: 0.4857\n",
      "dict_keys(['loss', 'mse', 'mae', 'root_mean_squared_error', 'mean_squared_logarithmic_error'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['loss',\n",
       " 'mse',\n",
       " 'mae',\n",
       " 'root_mean_squared_error',\n",
       " 'mean_squared_logarithmic_error']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting direct metric results using the metrics given to model.\n",
    "score = model.evaluate(test_x, test_y)\n",
    "print(history.history.keys())\n",
    "model.test_on_batch(test_x, test_y)\n",
    "model.metrics_names\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[2], score[2]*100))\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[3], score[3]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bavanya/Downloads/deb_packages/home/bavanya/Desktop/venv_python/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/bavanya/Downloads/deb_packages/home/bavanya/Desktop/venv_python/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: /home/bavanya/Desktop/6thSem/BTP/regression_PROMISE_dataset/saved_models/ant1.3_ant1.4_model1/ant1.3_ant1.4_model1_1/assets\n"
     ]
    }
   ],
   "source": [
    "# Saving the model\n",
    "model_id = 1\n",
    "path_to_save = '/home/bavanya/Desktop/6thSem/BTP/regression_PROMISE_dataset/saved_models/ant1.3_ant1.4_model1/ant1.3_ant1.4_model1_1'\n",
    "model.save(path_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the results to csv file.\n",
    "heading = ['model_id', 'train_data_name', 'test_data_name'] + model.metrics_names + ['fpa', 'clc']\n",
    "score = [model_id, train_data_name, test_data_name] + score + [float(Fpa) , float(CLC)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_id',\n",
       " 'train_data_name',\n",
       " 'test_data_name',\n",
       " 'loss',\n",
       " 'mse',\n",
       " 'mae',\n",
       " 'root_mean_squared_error',\n",
       " 'mean_squared_logarithmic_error',\n",
       " 'fpa',\n",
       " 'clc']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 'ant-1.3',\n",
       " 'ant-1.4',\n",
       " 1.3540980815887451,\n",
       " 1.3540980815887451,\n",
       " 0.9932464361190796,\n",
       " 1.1636571884155273,\n",
       " 0.4857074022293091,\n",
       " 0.4891347885131836,\n",
       " 0.4975334703922272]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the results to csv file.\n",
    "with open(path_to_save + '_metric_results.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(heading)\n",
    "    writer.writerow(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model and to make sure that the model is saved properly.\n",
    "model_loaded = load_model(path_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
